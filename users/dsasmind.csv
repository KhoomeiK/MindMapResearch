subreddit,self ID,parent ID,time,text
corgi,ff8iss5,t1_ff7zrnd,1579680421.0,as a german i must admit - this kind of nameing joke could have been pulledðŸ¤£
corgi,ff0cui8,t1_fezp736,1579467653.0,3 Potato rocket doggoneers to mars !
corgi,feylvhn,t1_feydezu,1579447346.0,Royal new overlords are pleased with your formal bow of speech !
corgi,fextfnz,t3_eqs57i,1579435743.0,could but our corgi girls brother :D
upcycling,fexs4gm,t1_fevvnjq,1579435278.0,thanks :)
corgi,fensazo,t3_epw7xr,1579290057.0,Totally awesome ! Love the Corgi-Fu style :D
corgi,femx2lu,t1_femr316,1579271860.0,"Haha - nice i wish you a lot of fun with him. Corgis are just awesome 

and actually Einstein is a girl :D"
corgi,fek8733,t1_fejxxeg,1579194635.0,Einstein is more less the same - during the morning she is greeting everybody in the office and tries to animated some people to play with her - but in the long run she is sleeping somewhere comfortable near me.
homelab,fejizw7,t1_fejgq17,1579176316.0,also Vegan to the bone !!!333
kubernetes,fej79kv,t1_fej4vkn,1579159854.0,"ah ok - understood. 

mhm, this is not easy doable with rook-ceph because rook only is the storage layer and doesnt know anything of the k8s world - beside its own resource name.

your also would need to dump everything out of k8s (etcd - yaml defs of deployments,sets,ing,services,pvc)

try [https://github.com/vmware-tanzu/velero](https://github.com/vmware-tanzu/velero) afaik with an (s3) minio backend it should be now able to backups everything (deployments,sets,ing,services,pvc+data) into minio and also restore it.

also rook-ceph support is tested it seems

[https://github.com/vmware-tanzu/velero/issues/1735#issuecomment-519373911](https://github.com/vmware-tanzu/velero/issues/1735#issuecomment-519373911)

if your test this with a test deployment please share the results :)"
homelab,fej4ypn,t1_feiecw8,1579157095.0,This is the way.
homelab,fej4xiv,t1_feibyx1,1579157058.0,\+1 for an embedded BBQ -  nor Singlepress Espresso  - nor RPiemulator + TFTScreen with controllers - Appliance
homelab,fej4r38,t1_fei1q5l,1579156864.0,"new startup idea !!!111 

PaperRack is born !!!11"
kubernetes,fej390c,t1_fej2z4m,1579155247.0,"uhm. create a new cephblockpool and storage class ?

im not quiet sure why you would pick such an approach. 

so you would need to post more information on your architecure how you will facilitate your deployments."
kubernetes,feipb0u,t3_ep0oji,1579143865.0,"the main reason why there is not a ""one-for-all-solution"" is that k8s diversity is overwhelming depending on what your k8s cluster use case will be.

\- Hosting WebFronted / REST Microservices via CI/CD

\- Facilitate the cluster as a Big Data project for Hadoop with spark and Cassandra

\- using one part of the cluster as own PVC Backend (ceph) solution to the whole cluster via rook

etc... 

there are multiple projects currently which aim for this - but to be honest they all have pros/cons  

[https://get-kapp.io/](https://get-kapp.io/)

[https://github.com/fluxcd/flux](https://github.com/fluxcd/flux)

[https://argoproj.github.io/argo-cd/](https://argoproj.github.io/argo-cd/)

[https://github.com/google/kasane](https://github.com/google/kasane)

[https://github.com/kubernetes-sigs/kustomize](https://github.com/kubernetes-sigs/kustomize)

and yeah helm. ([hub.helm.sh](https://hub.helm.sh) is your friend)

I hope this helps to get you started =\]"
kubernetes,feiodr3,t3_ep5w8g,1579143246.0,[https://rook.io/docs/rook/v1.2/ceph-block.html](https://rook.io/docs/rook/v1.2/ceph-block.html)
kubernetes,feio225,t1_feieb69,1579143031.0,"this depends on your Centos HA configuration. 

Without extensive testing in case of Hardware Node failures and heavy load on node usage would lead to the ops nightmares.

as example

Centos HA should treat & monitor as the 

Kubernetes Masters 

(3x minimum in K8S in HA)

\- monitor status of K8S Master node (response time/health/what to do when one is faulty)

\-  bootstrapping a replacing a faulty master node is different than a worker node

\- also to wait in for certain states to happen and not prematurely kill a bootstrapping new master which already is in the bootstrapping phase and sync data from the alive master nodes (no testing this could lead to K8S Cluster Split-brain situations AKA Ops Nightmares)

differently then 

K8S Worker nodes 

\- when to add new nodes in high load times

\- when to remove them

\- how to treat faulty nodes

\- monitoring Kube API endpoint for response times etc).

\- bootstrapping worker k8s nodes 

etc... to name some points. It's a bigger topic

found this post from a guy who did this in a similar setup - 

[https://datamattsson.tumblr.com/post/187582900281/running-traditional-ha-clusters-on-kubernetes](https://datamattsson.tumblr.com/post/187582900281/running-traditional-ha-clusters-on-kubernetes)

I hope this helps makeing a decision"
kubernetes,feijsz3,t3_epbp5q,1579140172.0,"this is maintained by nvidia themself and one way to do it.

https://github.com/NVIDIA/k8s-device-plugin/blob/master/README.md

the reademe pretty much describes what the plugin does in manual steps to the GPU nodes 
to expose, manage and monitor the GPU device resources to the kluster.

hope this helps to point you in the right direction"
kubernetes,fe4ztv2,t3_enq6za,1578864333.0,"im running rook now for over 2 years on a small baremetal setup similar like yours

1x Master Zotac Intel Atom with 4 GB RAM

3x Intel Nuc 16 GB Ram and 250 GB SSD

so some heads up that i already ran into

If you running older rook like 0.x  before k8s 1.11.x all should be good.

in between K8S included a new sub layer for storage managing called CSI ( i think around 1.12 it was included)

around this time CSI wandered into rook 1.x versions. Which gave me a lot of headaches (nodes locked up after 2 days and often i cloudnt mount pods PVC again)

3 weeks ago i upgrade to rook 1.2.1 and K8S 1.15.7 and currently PVC and the nodes are running really stable.

other solutions right now 

[https://github.com/kvaps/kube-linstor](https://github.com/kvaps/kube-linstor)

[https://www.chubao.io/](https://www.chubao.io/)

[https://github.com/libopenstorage/stork](https://github.com/libopenstorage/stork)

or local-path / NFS Storage which is with CSI now also posible

hence the fact that i currently wouldnt consider CSI as stable"
kubernetes,fdwwekj,t3_emp0cy,1578762948.0,"i have a baremetal k8s cluster at home
k8s 1.15.6
1 master
3 workers

the workers run rook with ceph for the PVC provisioning of the pods.

had for a quiet long time problems with the upcomming CSI impelementation which would kill the nodes every 2 days. 

upgrade rook to 1.2.1 last week and now the nodes dont die anymore! 

still not 100 % what the issue was. so lets see =]"
homelab,fdtcfxb,t1_fdt1mqc,1578714782.0,"if im guessing correct using a cli tool or creating a script around it is your first time.

so i have 2 options

1. Duplicati is just another tool and as far i could see/read it has a windows gui with a cron job feature so this should fit your needs

https://www.duplicati.com/download

2. or you go the learn something new road

its a shell script but i think its a good start and with the linux subsystem its also doable unter windows

https://github.com/wolfv6/rclone_jobber/blob/master/rclone_jobber_tutorial.org
https://github.com/wolfv6/rclone_jobber

or you use powershell

the rclone forum is pretty active - so this is also a good starting point
https://forum.rclone.org/s"
homelab,fdphpt5,t1_fdpg80v,1578628930.0,noice *thumup* didnt checked that far =]
homelab,fdpdxh9,t3_emhita,1578626165.0,"not sure which OS you're running but even with windows Subsystem Linux - rclone should do the trick

[https://rclone.org/](https://rclone.org/)

&#x200B;

* MD5/SHA-1 hashes checked at all times for file integrity
* Timestamps preserved on files
* Partial syncs supported on a whole file basis
* [Copy](https://rclone.org/commands/rclone_copy/) mode to just copy new/changed files
* [Sync](https://rclone.org/commands/rclone_sync/) (one way) mode to make a directory identical
* [Check](https://rclone.org/commands/rclone_check/) mode to check for file hash equality
* Can sync to and from network, e.g. two different cloud accounts
* Optional large file chunking ([Chunker](https://rclone.org/chunker/))
* Optional encryption ([Crypt](https://rclone.org/crypt/))
* Optional cache ([Cache](https://rclone.org/cache/))
* Optional FUSE mount ([rclone mount](https://rclone.org/commands/rclone_mount/))
* Multi-threaded downloads to local disk
* Can [serve](https://rclone.org/commands/rclone_serve/) local or remote files over HTTP/WebDav/FTP/SFTP/dlna

[https://github.com/rclone/rclone](https://github.com/rclone/rclone)"
worldnews,f0wqc20,t1_f0mwu1d,1569012015.0,"never said only - i only said that you posted a study from a publisher that gets money from the Pharamasector in the first place and this is not really trustworthy or solid.
 
In Germany we have here the Bertelsman foundation - if they post a study about how our great coolation keeps most of the promises... I look at it with hippo eyes - because the bertelsman foundation has a lot of ties into the polical sector and the CDU/CSU party.

The same fits your Article - but you know what....
Since you start beeing sarcastical about it and beeing defensive about posting an scientifc article - i will stop here. 

Get solid facts on board if you boast about the ""good"" pharmaceutical sector and that it costs to much money because of the process... 

Bottomline is - its a realy bad sad fact if you state this and tell the world we will not help to develope counter vaccines/antibotics to tackle multi bacteria/viruses...."
