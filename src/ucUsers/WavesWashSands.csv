subreddit,self ID,parent ID,time,text
visualnovels,fplxgat,t3_ge85i3,1588721347.0,"I'll put in another vote for voiced MCs, and I'd argue that for many VNs it's weird if the MC *isn't* voiced. I think Aiyoku no Eustia would not work as well without a voiced Caim, for example."
languagelearning,fplv47w,t3_ge5mth,1588720061.0,I clicked on the title expecting this to belong to /r/languagelearningjerk. I was disappointed.
languagelearning,fpluxrl,t1_fpkqhgs,1588719962.0,"Lol I'm personally big enough of a fan of Duolingo's method that I'm designing Duo-like materials for myself in my other target language. (i.e. cutting sentences from textbook recordings and making myself translate them from French). The last update on Duo's Japanese tree greatly expanded on it, and now they're some ways into N3 (but I can't tell you exactly how far into N3 it goes because I haven't finished the last part of the course).

I'm probably going to stop memorising vocab after N3 because most of the higher vocab I'll need for my purposes is shared with Chinese anyway (and even if it's not, dictionaries exist). (For vocab up to N3, I'm using Clozemaster as well as the readings deck on Memrise alongside Duo.) Grammar, though, I plan to study up to N1, so I'll probably pick up Bunpro as some point! I've never heard of it before - sounds like a pun on 文法 right?"
languagelearning,fpiiyz9,t1_fpgh71i,1588641884.0,"The Japanese tree gets updated very frequently, and it just got another update a few weeks ago, so depending on when you used it, your experience would likely be very different if you were starting now instead. I think the main problem with it is not accepting a lot of possible translations, which gets annoying from around the fourth or fifth part of the tree, and while you can report other possible translations, they're fairly slow to accept them."
visualnovels,fpihfbv,t1_fphz1oo,1588640967.0,"> looks at how it’s mostly girls that get the tsundere archtype

If you play some otome/BL, it's not at all uncommon to find male tsundere ... Not that they're necessarily insecure, of course."
visualnovels,fpigtef,t1_fph6liu,1588640610.0,"> So yeah, a demographic which like depressing stories and/or like interpreting stuffs? 

Well, there's no shortage of utsuge, and interpreting stuff was an important part of the denpa genre, which was popular at the time, and which Sayooshi is now one of the biggest representatives of. Also, >!the structure of the VN was parodying VNs like those from Key, where the protagonist's job is to 'fix' the heroines' problems. They wanted to make a VN where it's the MC who needs getting fixed.!<"
linguistics,fpfyo5c,t3_gd8ygs,1588588447.0,"Strictly speaking, synonyms don't exist. No two words have the exact same distribution if you look in a large enough corpus, which shows us that they always have slightly different shades of meaning. Of course, in reality there are words that are close enough that we may call them 'synonyms' without getting into much trouble, but this is really a convenient fiction."
languagelearning,fpfpon3,t1_fpep5sq,1588579020.0,"I could read simple texts in Japanese fairly comfortably with a dictionary just after a few months of mostly Duolingo. I sound like a completely moron if I actually try to speak it, and I have no pretension that Duo will get me to fluency especially for speaking/listening, but my goal in Japanese is only *reading* fluency (I have no motivation to know how to speak/listen), and Duo has played big enough of a role in that. Sure, Duo is not going to make you fluent, but to compare that with training for the army through Fortnite kind of gives Duo short shrift."
visualnovels,fpfiff8,t3_gbk6yr,1588572205.0,"I have a bunch of VNs that I've been meaning to review but never got round to it, because when I write a WAYR I'm usually the kind to post several 10k-character posts, and I don't always have the time for that. Looks like this is giving me the motivation to write more but smaller posts ..."
linguistics,fpely73,t1_fpcuszg,1588550110.0,"> But if prototypicality effects don't place any constraint on our theories of concepts, then the theories will need independent justification. 

Why wouldn't they? Even in the odd-even case, a satisfactory account would have to accomodate *both* prototype effects and classical-categorical effects. An account that only predicts classical ones wouldn't.

> That's where criteria like compositionality come in, for which things like prototypes fail radically.

I think it's not fair to evaluate this based on models that assume abstract prototypes are represented, given that most people no longer believe in this, and most people have moved to either an explicitly exemplar-based model or hopped on Elman et al's connectionist bandwagon (and I don't think the two kinds of models are in opposition). It is surely this kind of models that should be evaluated if we're going to make a claim that cognitive approaches can't handle compositionality.

> Red hair is just a simple example for expository purposes, but the principles are the same as in more complicated things like variable binding or quantifier scope.

There's a huge functionalist/cognitive literature on binding; in fact I'm working on something related. See Chapter 6 of Ariel (2008) as an example of a very detailed work on the topic.

Ariel, Mira. 2008. Pragmatics and grammar (Cambridge Textbooks in Linguistics). Cambridge: Cambridge University Press.

> First, he doesn't argue against innateness in this paper at least

He doesn't argue against the innateness of either the inclusive or exclusive interpretations, but he was arguing against an innateness bias towards the inclusive one, which had been previously argued on the grounds that kids hear the exclusive one much more often. 

> And second, he says that the exclusive meaning is derived from the inclusive meaning via a process of pragmatic reasoning. That's a Gricean account, whether he calls it that or not.

That was still part of the literature review. If you think about the actual model he proposes for a bit, it's consistent with exclusive being derived from inclusive, inclusive derived from exclusive, or (as I believe) neither is derived from the other."
linguistics,fpefta8,t1_fpcve3y,1588546719.0,"Sure, of course I agree we should control for these things, and I know it's not easy. I've sat through enough hours of discussion on how to control things to know that. My point is I don't see the value of 'theory' here. There is a huge literature on what kind of factors there are, and we can get the empirical facts by looking at that literature, no need to assume any 'theory'. The relative weight of constituents, for example, has well-known effects on parsing. There are different 'theories' on why this is the case, but we don't need to care about that when we design the experiment - all we need to do is to control for length."
linguistics,fpbxeca,t1_fpbtt1d,1588481249.0,"> If the first experiment has more than one interpretation, then running it a thousand times won't help, unless you explain why the alternate interpretations shouldn't also replicate.

If people simply find construction B easier to process because they hear it more often than construction A, but not because there is something inherent about construction B that makes it easier to process, then I would expect that the greater frequency of construction B is due to convention, right? But if we find across unrelated languages with no known history of contact that the same pattern applies, then either we're simply lucky in finding languages that all happen to have a bias towards construction B, or we may conclude that even if there's a conventional component in it, the convention formed because it is favoured by processing.

(I might have put myself in a trap when I said token frequency earlier. What I would actually do is build a model that contains other factors like lexical frequency, animacy, topicality, etc.)

> It's not pedantic at all, particularly if you're trying to compare these things across languages. To take just your example, some languages have a topicality restriction on the subjects of passives, but not transitives. This means that saying 'a man was bitten by a dog' presupposes a salient man in the discourse, even though it can describe the same situation as a transitive sentence. It's been shown that accommodating presuppositions invokes a processing cost. But you wouldn't expect these languages to use the passive less than e.g. English- the increased processing time is a side effect of its communicative function. For any given construction it's usually pretty easy to find similar small differences that could lead to a difference in processing time. They can potentially be controlled for, but only with a theory that specifies the structures that are involved. Just saying 'these two sentences describe the same thing' doesn't even come close to the level of detail required.

Well, English also has a constraint on topicality of passive subjects; it's just a soft constraint rather than a hard constraint ... Pedantry on my side aside, I agree that we should be controlling for this difference. In this case, if I were the experimenter, I would ensure that in both experiments, the context is such that all the entities involved have the same level of accessibility (as well as animacy, person, etc.). But the effect of topicality on the use of a passive is an empirical fact (and one that is universally known at that). We can control for that regardless of whether we have a theory of why this is the case.

Actually maybe if it would be simpler for me if I chose an easier example: Let's say I find that there are two sounds [x] and [y] such that x -> y is much more common historically than y -> x. Then I conduct a perception experiment and find that people speaking languages with both sounds answer [y] when they actually heard [x] much more commonly than the other way around. Then surely this is a significant result regardless of whether I have a theory of perception?"
linguistics,fpbu1f2,t1_fpbqmjo,1588478712.0,"> odd and even thing

I mean, sure, we're definitely cognitively capable of dealing with classical categories. That is surely trivially true, otherwise the entirety of modern mathematics would have been impossible to create, since it hinges on axioms and definitions that are defined in terms of necessary and sufficient conditions. The point is that Gleitman et al. don't show that this is the case for the kind of words that linguists are usually more interested in, like 'place', 'cause', 'love' or 'table', or the many other words that arose naturally rather than being created by mathematicians. I can accept that both prototype effects and classical categories exist in the very restricted context of mathematics, but I have no reason to care about classical categories in anything I do in linguistics, since I don't work on mathematical texts, and I see no evidence that grammatical morphemes and the majority of lexical items that linguists deal with are defined with classical definitions.

Edit: I think I see what you mean now - you seem to be talking more about the reasoning behind it - but my reasoning would be the same. Sure, you can say that prototypical effects don't entail the lack of a classical definition, but why should I care about classical definitions unless there's possible evidence that they're involved?

> When these models can deal with the kinds of things in an introductory semantics textbook like OP mentioned, we can discuss how they deal with compositionality.

I haven't read the OP's textbook, and I don't know what type theory and logical form are supposed to mean, but - and correct me if I'm wrong - I assume those aren't the same as the kind of composition that Gleitman et al. were talking about? They were literally discussing things like red + hair = red hair.

> This was basically my first reaction, but it falls apart right away. Without further specification, it predicts that it would be infelicitous to say 'They have three or four kids,' since having four kids entails having three kids, just as being Californian entails being American. There are ways of preserving your initial intuition, so that 'He is American or Californian' is redundant and 'They have three or four kids' isn't. But doing this requires specific theories about how or works, and they have consequences that can be tested.

But this is only a problem if you assume, as in the classical approach, that words map onto concepts (in this case, onto a symbol in predicate logic). A cognitive linguist who uses the words-as-cues model will have no problem with *or* displaying different functions depending on context. Again, I'm not familiar with this literature, maybe some cognitive linguists have worked on it and maybe not, but I don't imagine cognitive linguists would have problems with it.

> The theory literally says that children derive the exclusive meaning by Gricean reasoning from the inclusive meaning (and note that they don't attempt to explain where the inclusive meaning comes from or why kids start with it).

If by 'the theory' you mean Jasbi's, I think you're misreading his paper. The only place he talks about the Gricean account is in the literature review. All his model says is that kids can identify which reading is intended using contextual cues, even with the limited input they receive, and he explicitly argues against the idea that kids are innately predisposed to the inclusive interpretation."
linguistics,fpbn2x1,t3_gcet52,1588473846.0,"> a normal (textbooky) conversation

It's definitely what a 'textbooky' conversation looks like, but I would avoid equating that with 'normal'. Actual typical conversations, even in English, often do not have definite starts and ends, let alone one that is clearly demarcated by formal greetings. If you look at a corpus that was collected with naturalness as one of its main goals, like the Santa Barbara Corpus of Spoken American English, you'll find a plenty of conversations that don't start like this.

To answer your question, in Tibetan the first greeting that's taught is usually བཀྲ་ཤིས་བདེ་ལེགས *bkra.shis.bde.legs* (good fortune), but (at least from what I've learnt) this is reserved for important situations like in new year or when you haven't seen someone for a long time. Usually it's much more common to say something like ག་པར་ཕེབས་ག་ *ga.par.phebs.ga* (Where are you going) and སྐུ་གཟུགས་བདེ་པོ་ཡིན་པས། *sku.gzugs.bde.po.yin.pas* (Is your body well)."
linguistics,fpbhr4o,t1_fp8xpuw,1588470294.0,"> I would guess, though I am not a linguist specializing in dialects of Chinese, nor do I speak any dialects other than Beijing Mandarin, that conservative languages like Teochew probably use fewer binomes because they preserve more non-homophonic pronunciations of words.

Yeah it's a general observation that Southern dialects have retain more monosyllable words. I don't speak Teochow but in Cantonese for example, 'eye', 'nose', 'mouth' and 'er' are generally just 眼, 鼻, 口, 耳, although you can also say 耳仔 for ear, and 眼睛 sounds okay in a formal context.

I would point to formal letter writing (at least as it's done in Hong Kong and Taiwan, Mainland China seems to have adopted a relatively lax style) as a good example of heavily wenyan-influenced written communication is like. Speaking like that to anyone would of course be very weird."
linguistics,fpbh2tp,t1_fpb38ld,1588469848.0,"> What got me thinking about this was me wondering how much variance there is in the amount of distinct sounds between languages. Do languages tend to congregate around a certain number of sounds? Are there notable outliers?

You might want to look into the literature on phonemic inventory size. There is a lot of work on this, both on inventory sizes themselves (particulraly by Ian Maddieson, e.g. Maddieson 2005), as well as a fair bit of ~~drama~~ debate on the relationship between inventory size, population size and serial founder effects.

Maddieson, Ian. 2005. Issues of phonological complexity: Statistical analysis of the relationship between syllable structures, segment inventories and tone contrasts. UC Berkeley PhonLab Annual Report 1(1)."
linguistics,fpbe9p1,t1_fp9ls8j,1588468009.0,"> No, people were literally asked to rate things on a scale of 'oddness,' exactly as in the original Rosch experiments, and said that e.g. 371 is 'more odd' than 9. People of course have a system of arithmetic in which odd and even are not gradable. Gleitman and various coauthors (here's an overview) argue that this shows that concepts can have prototype structure associated with them, without literally being prototypes. If this is true, it casts the whole enterprise into doubt, since prototype effects cannot be directly taken as evidence that a concept is a prototype. To be clear, this doesn't make all the work in prototype theory invalid or uninteresting. But it does mean that prototype theory can't be the full story when it comes to concepts. The implications for importing prototypes (or exemplars) into linguistics should be clear. We probably shouldn't be trying to give a prototype theory for logical connectives, for instance (though I'm not sure anyone has tried).

I think it is a bit of a straw man to assume that all people working on prototypes believe that concepts *are* prototypes. Rosch herself said that prototype effects don't necessarily entail that prototypes are actually represented in the brain and that to speak of prototypes is a convenient fiction. I think most cognitive linguists nowadays would be much more in favour of an approach that treats prototypes as emergent, given much of the evidence against stored abstract prototypes in our heads. There is little reason to believe that abstract concepts have to exist.

I read the article briefly, and I wouldn't say I'm convinced. The categories for which people always judged membership to be categorical were odd, even, plane geometric shapes, and all these are technical concepts that kids learn in maths class, and can probably assume to have necessary-and-sufficient-conditions-style definitions. But surely this isn't the case for the majority of words that are acquired, and that linguists are mostly interested in. Perhaps their argument is significant for psychologists studying mathematical cognition as well as perhaps linguists who work on the intersection between that and language, but I don't see this as a relevant argument for most linguistic work.

As for their compositionality argument, I'm not familiar with this literature, but their arguments seem to depend on specific models of compositionality that were available at the time, but they may not be valid when applied to current approaches, say word2vec, that treat words as contextual cues rather than objects that 'have' meaning.

> Thanks for the paper. I was asking about work on the semantics itself though, not acquisition. (For example, is there a cognitive linguistics literature on Hurford's Constraint? My impression is that nobody really works on this kind of thing.) 

I just googled that and I'll be honest, I don't see much point in studying this kind of constraint that involves constructing weird sentences and trying to explain why they don't pop up, and I suspect I'm not alone in that judgement. However, I don't see how any cognitive linguistics analysis would have trouble explaining this. I mean, if you just want to say that someone is American, then 'He is American' is just as informative as 'He is American or Californian' but has a much lower production and processing cost. It seems unmotivated for a language to develop a construction like 'He is American or Californian'.

> Worth noting too that there is a lot of evidence now against the Gricean theory of implicatures that the paper assumes. The existence of embedded implicatures, for example, is strong evidence that implicatures are grammatically, not pragmatically computed. And there's actually evidence for this in the acquisition of disjunction: children go through a stage where they interpret or as and. I don't think there's any way for Jasbi et al's model to account for this.

I'm not familiar with embedded implicatures, and I don't think I'll read the paper you linked here tbh, but I don't think the the model in Jasbi et al hinges on any assumptions about Gricean implicatures. That the conceptual and prosodic cues he propose enable kids to distinguish between the two seems quite independent of any model of discourse/pragmatic processing. In any case, I don't subscribe to a model that separates code and inference, and from talking to Jasbi, I suspect that he himself would not, as he's moving towards the words-as-cues model as well."
linguistics,fpb46g8,t1_fp9moax,1588461740.0,"> I would be pretty skeptical about such claims. How would you tell which direction the causality goes? A sentence could have less tokens because it takes longer to process, but it could also take longer to process because it is less frequent. And there could be many irrelevant reasons for one sentence to be less frequent than another. Typological comparison introduces even more potentially interfering variables.

Sure, we can always find room for alternative interpretations of the data. My response would be that if we repeat the experiment and corpus study over and over in languages that are phylogenetically distinct and have little evidence of intense contact, then it's unlikely it was a fluke, and it is likely that there is some processing motivation behind the greater token frequency. In any case, I don't see how the same criticism would *not* apply if we had a model of parsing.

> And in any case, to even make these kinds of comparisons, you need evidence that sentence A is relevantly like sentence B. For that, especially in crosslinguistic comparison, you need a theory of what they actually mean.

It sounds a bit pedantic honestly to say that, say, we need to provide evidence that 'He stole my wallet' and 'My wallet was stolen by him' describe the same situation. But even if we did, I don't see how a theory of meaning would help. If we were going to demonstrate that, surely we should be doing it empirically, say by asking a bunch of people to rate the similarity of the situations described by these sentences. If anything, a theory-neutral measure of similarity would constitute *superior* evidence to a theory-based one, to the extent that the latter exists at all."
badlinguistics,fpb38ot,t1_fpaxnm6,1588461181.0,"The funny thing is that space -> time metaphors are very common in language. If I were them I probably would have used 時/とき; unless they can come up with sound changes with from a common protolanguage that leads to 'tokoro' in Japanese and 'toki' in Basque, I think that actually sounds *more* convincing."
linguistics,fp8yffv,t1_fp6jrws,1588407436.0,The [languoid CSV](https://glottolog.org/meta/downloads) on the Downloads page should have the family IDs. I know because I downloaded and used it for a project not long ago - are you using that?
linguistics,fp8y7x9,t1_fp2714u,1588407215.0,"> There's no interest in sentence A taking 30ms longer than sentence B unless there is a theory that links the parse to the grammar.

I'm not sure this is true. Surely, for example, if sentences with similar properties as sentence A are less common among the languages of the world than those similar to sentence B, or sentences like sentence A have much lower token frequency than those like sentence B in corpora of a certain language, then this experiment is already valuable in that it reveals a possible processing motivation behind observed patterns? Of course it would be nice to have a model from which the RT difference is derived, but I don't see how there's 'no interest' in the experiment without it."
linguistics,fp8s83c,t1_fp37ur9,1588401268.0,"> Lila Gleitman has shown, you can induce prototype effects with concepts like 'even number,' which is, well, not ideal

I'm not familiar with mathematics cognition, but would I be right in assuming this means that when people are asked to tell between even and odd, things like, idk, 232 and 648 have shorter RTs than things like 134 and 790? Why would that be not ideal?

> I hope someone with more knowledge of cognitive linguistics will correct me, but as far as I can tell there is very little work on the kind of phenomena that formal semanticists work on.

Masoud Jasbi has some work that refutes some formalist claims on logical connectives:

> Nevertheless, the success of this model suggests that the systematicity of children’s linguistic input might allow them to decide correctly between exclusive and inclusive semantics for disjunction. Such a learning account would obviate the need for a principle that directly blocks exclusive disjunction as a possible connective meaning. *or* may not be assigned an exclusive meaning simply because such a mapping is not supported by the language children hear.

Jasbi, Masoud, Akshay Jaggi & Michael C. Frank. 2018. Conceptual and prosodic cues in child-directed speech can help children learn the meaning of disjunction. In CogSci."
linguistics,fp5d44z,t1_fp4v4hc,1588324884.0,"I believe u/dom's point is that the way you restrict your interest does not seem principled: the LMC split is not any 'lesser' evidence for the plausibility of the Japonic split that you mention simply because it involved splitting four tones instead of going from no tone. Besides, modern typology (especially phonological typology) increasingly places the emphasis on diachronic processes anyway; there are some people who go as far as to say that typological explanations aren't meaningful unless you can show a diachronic process that leads to it. Finding correlations and patterns isn't the end goal of typology; the end goal is to find out the processes (including phonetic mechanisms, universal pressures on communication, historical migrations and contact, etc.) that led languages to look they way they do now."
linguistics,fp56qvw,t3_gbceb7,1588318226.0,"In Hong Kong, I believe its popularisation was due to [an emoticon](https://evchk.wikia.org/zh/wiki/Sosad) on the HKGolden forum that you get if you type [sosad]. One piece of evidence for this is that it is usually written as 'sosad' rather than two separate words, and intuitively I feel the two are used in similar contexts. Not sure where it originated from before that, and whether the use spread from HK to Mainland China or was an independent innovation."
UCSantaBarbara,fp55npz,t3_gba8xl,1588317131.0,"Slightly off-topic, but last time I went out, the Albertsons and Smart and Final stores in Goleta had some stock of toilet paper. Target was still out though. Not sure about the situation in IV, and not sure if I was just lucky."
linguistics,fp4f0ti,t1_fp3zaop,1588297641.0,"Lhasa Tibetan would be an obvious one then. Ignoring the ongoing losses in codas and tone splits (which would massively complicate the discussion and put the language in your 'six or whatever' category), voiced consonants (including nasals and approximants) got low tone and aspiration, while voiceless consonants got high tone and kept their aspiration status. There's a bunch of other complexities concerning the loss of initial clusters but I imagine that wouldn't be relevant to Japonic. I believe Zhigatse works the same way, but other tonal varieties of Tibetan will have different patterns."
horrorlit,fp4056z,t1_fp3kkld,1588289095.0,"Nope, there are no supernatural elements."
vnsuggest,fp3uwkf,t3_ga3ehj,1588286259.0,Not sure why you liked Natsuki specifically but Haru from Raging Loop and Mizuha from G-senjou no Maou might be good places to start looking.
vnsuggest,fp3umzi,t3_gaune2,1588286116.0,"Look at the denpa genre. They always have a strong focus on atmopshere, and may have some surreal scenes. [Kyojin-tachi](https://vndb.org/v19216) and [Sayooshi](https://vndb.org/v1200) would be my recommendations."
vnsuggest,fp3ufw0,t1_fp1yrg7,1588286012.0,"There are psychological horror elements for sure - they're just not heavy and you're not going to be scared by them. The anime is universally hated even by those who enjoyed the VN, though the VN itself is kind of hit and miss - some people love them, others don't."
linguisticshumor,fp3u1eq,t1_fp3jkyt,1588285797.0,"Yeah. There's also *chiffre*, which is a bit like 數字."
linguisticshumor,fp3icjn,t1_fp3i5p7,1588279813.0,My guess is that comes from French *numéro* vs *nombre*!
linguisticshumor,fp1h455,t1_fozxztq,1588235334.0,"In text, not really, unless 198 is not a quantity of something but e.g. if it's a year or a 號碼 (= 番号 if you don't know the Chinese word, not sure how to express this in English to exclude numbers expressing quantity). But if you're e.g. telling me a bunch of numbers I have to write down, 一九八 is fine."
linguistics,fp1fiw9,t3_ga80ls,1588233793.0,"In the interest of adding a new data point, Tibetan media (at least from the Tibetan learning Instagram account that I follow plus my five minutes of googling and checking the dictionary) seem to call it with some variation on ཏོག་དབྱིབས་ནད་དུག་ *tog.dbyibs.nad.dug* (which describes the virus as 'crown-shaped' similar to 冠状)."
AskReddit,fp1eryp,t1_fp1dkmj,1588233093.0,"I'm also vegetarian. We started getting veggie burgers a couple years before I came to the US for the first time; there's a dude making 'new' kinds of meat substitutes that got particularly successful after the surge in pork prices during the African swine fever outbreak. I don't find it weird or gross, but I certainly wouldn't say I love them either."
AskReddit,fp1e3cs,t1_fp1dp6k,1588232460.0,"Huh, that's interesting. I wonder when exactly it got here.

Oh also we have a vegetable that's super similar to lettuce and is always cooked, so I guess analogical thinking could be one reason we don't find it weird to cook lettuce. I don't know what it's called in English and my google-fu fails me at the moment but it's called 油麥菜 in Chinese."
AskReddit,fp1djts,t1_fp1cxlq,1588231955.0,Hong Kong
AskReddit,fp1djmj,t1_fp1cs14,1588231950.0,"I do, now you know lol."
AskReddit,fp1djcx,t1_fp1com3,1588231944.0,"> I have never heard of anyone in my life who cooks lettuce.

Lol well this wouldn't be the first time I hear this from a Westerner. We put lettuce in salad too; I believe salad itself originates from the west anyhow. But we definitely cook lettuce in regular meals."
AskReddit,fp1dfg8,t1_fp1cez9,1588231840.0,I guess there's no accounting for tastes lol.
AskReddit,fp1btfy,t3_game7o,1588230372.0,"As a vegetarian the main thing I'm weirded out by is the stuff you eat raw. Lettuce I understand, I usually cook lettuce but I'm totally okay with eating it raw too. Carrot is also still okay. Broccolli and cauliflower is when it gets a little weird, but spinach is definitely weird - they are so much better cooked. What I really cannot comprehend, though, is why anyone would eat *mushrooms* raw."
visualnovels,fp17p5u,t1_foytjft,1588226776.0,"Tsukiko from [3days](https://vndb.org/v1085)? I don't recall too many jokes, but otherwise she fits the bill."
linguistics,fozzq9l,t1_fozvpfl,1588199783.0,"> I am not entirely certain which subfield of linguistics I’d like to pursue, but I am leaning more toward the humanities/historical approach than the neuroscience side of things. I am also very interested in classics and philosophy, so if there is any program in particular that is also known for those connections, that would be ideal. 

Given this bit of information, Yale seems to be the best choice, especially with Claire Bowern there. Brown's linguistics is housed with psychology so it leans more to the 'social sciency' side; they do have more 'humanities-side' stuff, but don't seem to do any historical. Princeton leans more towards the 'humanities side', but the person working on historical doesn't seem to focus as much on it as Claire Bowern does, plus you seem to prefer Yale's location, so the two added together seem to favour Yale. I agree that linguistics might not be the best option for you though..."
Cantonese,fozy6tw,t3_gabhc9,1588198982.0,"> 你係John呀

>你係唔係John呀?

Just a quick note in addition to the responses you've got, 呀 has different tones in the two cases. The first one should be aa4 or aa5, while the second one should be aa3. If you say aa3 in the first sentence, it would be interpreted as a statement."
linguistics,foziwkv,t1_foyr6yn,1588191419.0,"No, because this isn't how syntax is or should be done. While there was a time when this style of research was acceptable in some circles, modern standards require a solid empirical basis, often with data from actual language use, or from carefully controlled experiments."
linguistics,fozih21,t1_foyqxhz,1588191211.0,"I don't know much about the undergrad programme itself beyond chatting with someone who did her undergrad there, but the department is definitely well regarded in linguistics with several well known and respected faculty members."
linguistics,fozhqyv,t3_gafi2e,1588190862.0,"> my undergrad research project got canceled

What kind of project was it (capstone project for a class, RA work etc)? If you have the time right now, maybe you could start a new, unofficial one that does not require collecting your own primary data but only relies on others' secondary data, and ask a professor to help advice you remotely? That way you can still get a decent writing sample. Typology is a bit hard to do at the moment with libraries closed down, but you could do a meta-analysis of previous experimental work (since most experimental work is published in journals rather than monographs and should still be accessible) or work on some open-access corpus data.

> Additionally, seeing my and other universities struggling financially after only a month out of school makes me fearful of PhD, research and professor opportunities in the next few years even more so that I already was with the PhD market pre-covid.

Although universities are struggling financially, the struggles aren't really limited to universities; businesses and other institutions are also struggling. I have a cousin born in the same year who has been unemployed for months, while I'm still doing relatively well in grad school. So I think it is a struggle either way. Rather than giving up getting into a PhD programme altogether, I think it is wisest to keep both options open."
linguistics,fozewqx,t1_fozbzjk,1588189506.0,"Because people assign political meaning to it, as we can clearly see from the evidence that u/nae_co presented? Even ignoring the fact that not 'all' diseases are named after the place they originated in (even if you limit yourself to infectious diseases with known sources, SARS and H5N1 are some recent counterexamples that come to mind), the argument that previous diseases like MERS, ebola and Spanish flu were also named after places is not a good one. Naming conventions change over time and what was one maybe a relatively neutral way of naming things can definitely become political when its use is correlated with people with a certain political position."
linguistics,fozdqap,t1_foy2gbm,1588188948.0,"It's blatantly political in Hong Kong too. The probability that a media outlet will use 武漢肺炎 after February is directly correlated with how 'yellow' they are. Apple Daily mostly has 武漢肺炎 and uses it as a tag even in articles that sometimes use 新冠 whereas Wen Wei Po would only use 武漢肺炎 when *mentioning* it, not when *using* it. There is also a lot of explicit discussion about the naming; many people choose a name consciously to affect their position on the issue."
linguistics,fozcx1o,t1_foylmcw,1588188558.0,"The effect of the pandemic has been a sad but perfect example of Irvine and Gal's notion of fractal recursivity. It has led to anti-Hubei sentiment in China, anti-Mainland sentiment in the greater China region, anti-Chinese sentiment in Asia, and anti-Asian sentiment worldwide.

Gal, Susan & Judith T. Irvine. 1995. The boundaries of languages and disciplines: How ideologies construct difference. Social research. 967–1001."
linguistics,fozcdtn,t1_foy591j,1588188302.0,In Hong Kong people have been shortening it to 武肺. Not sure what Japanese people would feel about ぶはい though ...
GradSchool,fozb70q,t1_foz3976,1588187736.0,"> Why is knowledge production so focused on data for you? Surely all knowledge production and intellectual pursuits aren’t purely forwarded by quantitative collection and analysis of statistics?

> Edit for context: The reason I ask, and to tie back to the larger discussion, is because not all knowledge advancement just comes out of thin air from quantitative research. We often need to examine and understand past theories and concepts in order to build our own and advance things further.

I'm not sure why I came across this way but I didn't in any way want to dismiss the importance of qualitative data. My work itself is largely quantitative but I am totally aware of the qualitative work that went into establishing categories, generating hypotheses etc that I build on and sometimes have to do myself. However, there's nothing about qualitative research that makes it necessary to present it in a convoluted way. Martin Haspelmath is an example of a purely qualitative researcher who has crystal clear writing (and had a great influence on me).

> Additionally, on your use of Silverstein as an example, you say yourself that somebody was building upon that previous text, so there was use in it however it was presented. Sometimes it takes rehashing ideas a few times to boil them down to their base and more easily digestible components (though I’ll admit that I’m not completely familiar with Silverstein and the research you’re citing).

Sure, and I'm not saying Silverstein's piece was useless. He presented a new way of interpreting data from some previous studies without presenting new data and that's fine; I'm just saying that his presentation was unnecessarily complicated and unclear, frustrating even. I don't think the issue is with the idea being new. I've read other writings from both Silverstein and Eckert and I think it's clear that Silverstein writes to confuse the reader while Eckert writes to elucidate.

> Overall, I’ll say though that I understand academics can sometimes over complicate work in order to make things seem more complex and “Academic.” But I think we should be wary of just using this as a blanket explanation for anything that is challenging.

Sure, but I don't get the sense that this is what's happening in this thread."
GradSchool,foz2xty,t1_foy5xwb,1588183786.0,"> Like that’s what we do as academics, engage with intellectually challenging research and pursuits.

But surely our intellectual effort is better spent on activities that are actually necessary for advancing knowledge, like looking for patterns in data, looking for gaps in the literature, designing studies, collecting data, interpreting data, etc., which are challenging enough, rather than deciphering unnecessarily convoluted writing?

> When it comes down to it, what one might consider “gibberish” often changes depending upon knowledge base. I don’t know what your field is, but as someone in the humanities, there’s a chance if it’s in the hard sciences that it would initially read like gibberish to me.

While I've heard this argument before, I really don't think this is the usually the case with papers that people complain about. I'm from the humanities and some of my work has some overlap with the social sciences, though I have some STEM background, and I think that the humanities papers I find to be deliberately obfuscating are *way* harder to read than papers from the STEM field that I only have an undergrad background in, or in the social science field that some of my work overlaps with (even though I don't have a formal background).

I have never needed to read Foucault or anything remotely related to his work (maybe funny considering that my work also heavily uses the word 'discourse'), so I can't speak to his writing, but my current pet example of writing that's close to gibberish is [Silverstein (2003)](https://www.sciencedirect.com/science/article/pii/S0271530903000132). He has sections discussing Brown and Gilman (1960) as well as Labov's New York City experiment, *which I'm familiar with*, yet I am completely stumped when I try to read Silverstein's discussions of these studies. And when I read [Eckert (2008)](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9841.2008.00374.x), which builds on Silverstein (2003) and is extremely well written, I instantly understood what Silverstein's main idea was. Considering that I am familiar with the literature that Silverstein was citing, and that I had no trouble understanding literature that cited Silverstein, I think I have good reason to believe Silverstein was making his writing needlessly and deliberately obfuscating."
visualnovels,foxt079,t1_foxsx5y,1588155254.0,"No, but they're working on it and there's already a partial patch."
GradSchool,foxsge7,t1_fow15re,1588154695.0,"> 19th century/early 20th century anthropology is absolutely some of the worst sh*t I’ve ever read

Out of curiosity, how do you feel about reading Sapir?་Personally I'm a fan of his writing (as I suspect most linguists are) but I'm curious what anthropologists think about him."
visualnovels,foxs3my,t1_fos39l6,1588154340.0,"There's also [Gore Screaming Show](https://vndb.org/v933), which is pretty good plot-wise and has some 'fear of the unknown' elements especially at the end of the earlier routes."
GradSchool,foxqq39,t1_fowrvcp,1588152948.0,"I agree 100% that we should be able to decompose the jargon into simpler constructs, but I tend to avoid using words like 'simple' for this, because I don't agree with the usual implication that if you understand something you must be able to explain to a child or your grandparents. To use your example of the elastic net, we could decompose it into smaller and smaller concepts but eventually we'd still have to use words like 'objective function', 'optimise'/'minimise'/'maximise', 'parameter', 'absolute value', etc., that taken together don't mean much to most lay people, who don't necessarily have the background required to even understand why we're trying to optimising a function or what estimating parameters means (even if they knew what that meant).

With that said, again I'm 100% on board with the idea that we should be able to decompose those ideas. I think there's a big, endemic problem in my own field (linguistics) that people don't and often can't define simple concepts like 'subject' and 'pronoun' because they're intuitive enough for them for the languages they work on. And the result is that the meanings of these terms can change over time and in different ways in different regions and research traditions, usually without people being consciously aware of it. (There is a certain research tradition that loves redefining terms to confuse outsiders, but that's a separate issue.)"
GradSchool,foxppt2,t1_foxja3b,1588151922.0,"Eek, I didn't know he had stuff as bad as this ... The voicing thing does sound recognisable as I've seen him talk about it in another paper (but I have no idea how it would be applied to money ...). Fortunately (or not?) this isn't the work I'll have to read; I'm thinking of his early work on discourse and grammar in Lhasa Tibetan, which I imagine would have been more substantive."
linguistics,foxoqsu,t1_foxktz8,1588150942.0,"To be clear, I was only using tonogenesis as an example of a well-understood change, not implying that it's relevant. I could have used, say, final obstruent devoicing instead; tonogenesis was just the first process that came to mind for me in this context."
GradSchool,fowq1bu,t1_fovuqga,1588124751.0,"For me it's much less than a clean-ish first draft. Are you at a school with a semester system? I feel like when you're in the quarter system, there's no way a class paper is anything more than a pilot study. There's simply no time to gather all the data that's needed. So I end up with a ton of half-baked papers that I want to finish during the summer ..."
GradSchool,fowpto4,t1_fowfn0z,1588124630.0,"> the issue with the latter is that most musicologists don't have enough training in other fields to be able to credibly apply them to music.

Though I do think there are cases where it's probably credible. I don't know much about musicology (outside of some connections to phonetics that I know about because of a friend) but there's a professor at my school who borrows ideas from linguistics to study music theory, and we're pretty impressed by it."
GradSchool,fowpcfy,t1_fovtapu,1588124360.0,"> the language is only as complicated as it needs to be

Honestly, in my field, if you want to publish in one of the big (i.e. cross-subfield) journals, the accessibility requirement is really high and I've had to go through several rounds of 'watering down' a  paper because the editors and reviewers didn't find it accessible enough. Like, every little thing, no matter how small, needs to be explained, preferably with a diagram. It ended up blowing up the size of the paper and left me wondering why we couldn't just send readers to the references if they didn't know something ..."
GradSchool,fowp06c,t3_g9utr8,1588124162.0,"In linguistics, mainstream English writing tries to keep it as simple and clear as possible, but it's impossible to avoid jargon. The jargon is itself easy to pick up anyway so it's not a real issue. Writings in French, Chinese, and what I've seen in Japanese are pretty straightforward as well. However, I've heard from a professor that German papers can get pretty intense; at one point apparently some German linguists believed that if you write too simply, you're insulting the audience. I don't know any German so I've never had this problem lol.

*However*, the overlap with anthropology is another matter. I've had a class where we had to read some ling anth papers and some of them were cool, but some were really. brutal. I'm looking especially at Michael Silverstein and his students. I don't think it's a 'big words' thing or even a jargon thing though. It's just the way they structure their sentences and organise their paper etc. I'll have to force myself to read some more stuff by Agha (a student of Silverstein) because it's close enough to my research, wish me luck lol."
badlinguistics,fowdmtp,t1_fouw8bl,1588117745.0,"Sure, but I still think it's misleading to say that it's 'about as wrong' as the English/French example, because Chinese and Japanese are clearly in different language families and there are no verified or viable proposed connections between the two, whereas English and French are both solidly Indo-European. Plus 'family' is generally understood to mean the highest level that has received consensus support, and from what I've seen in the literature when people use the word 'family' to talk about subgroupings, they either explicitly say that they're using the term in a different way than usual, or get called out by other people for the misuse of terminology."
linguistics,fowd1r2,t1_fovdx76,1588117426.0,"Thing is, for some changes (e.g. tonogenesis) we have a very good idea of the phonetic mechanisms driving those changes. I think this is the kind of explanation OP would be interested in. But we don't know as much about changes in tonal contours: we know it can go in all sorts of wacky directions, but don't yet have a good idea of the mechanisms behind the change."
linguistics,fowcvfm,t1_fouf23x,1588117329.0,"Or two, though it does make me uneasy that the parameters aren't jointly optimised but separately. I do vaguely remember reading somewhere that it doesn't make too much of a difference though."
Scholar,fovuua9,t1_fovm1ia,1588107912.0,thanks solution verified
badlinguistics,foudh20,t1_fotybt9,1588081938.0,"Especially as, outside of Bai, Tujia and Karenic, almost all languages related to Chinese are SOV ..."
linguistics,fou032v,t1_fotxp5l,1588072163.0,"I see. That's a slight variation on a fairly standard design. What I suggest doing is to fit a mixed-effect logistic model. The maximal form of the model should have fixed effects of grammatical gender, an interaction between grammatical gender and whether the participant feels grammatical gender influenced their decision, and random intercepts for item and participant, along with a random by-participant slope for the effect of grammatical gender.

See [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613284/) for details and an example. Your formula should look something like this:

> Response ~ GramGend + GramGend:FeelGramGendRelevant + (1 | Item) + (1 + GramGend | Participant)

The main difficulty in your case is that the dependent variable has three rather than two categories. There are ways you can do this, but the standard package (lme4) cannot. You can either stick to the standard lme4 approach but opt to discard the robotic data, or to use a more advanced package that an handle three or more categories. I recommend [brms](https://cran.r-project.org/web/packages/brms/index.html) if you are allowed to use a Bayesian framework; the syntax is almost identical to lme4 so for now there should be no additional learning curve once you've learnt lme4."
linguistics,fotxa6b,t1_fotx3ax,1588069424.0,"Some keywords you would want to be looking at are outlier detection and power analysis. It would be ideal if you can learn statistics from scratch so that you can understand the underlying concepts, but since you're working on your dissertation that's probably not feasible ATM, so we can just point you to the techniques you can use. However, first we need to know what kind of experiment you'll be designing, since without the details of that it's impossible to answer. Is there any experimental paradigm from the literature that you will be following? What kind of answers are you collecting?"
horrorlit,fotwyry,t3_g9gkjo,1588069104.0,"Edward Lee, *The Black Train* takes place in the South."
badlinguistics,fotwgd0,t1_fotvb9z,1588068583.0,"Generally, when we talk about language families, we are referring to top-level classifications with sufficient support, in this case Indo-European."
linguistics,fotppzo,t1_fotp0lw,1588061737.0,"> , including sub-syllabic ones like 兒, isn't that reason to believe that the morphology in Old Chinese was likely no longer productive by the time the characters were developed, otherwise they would have come up with characters for it?

They probably weren't particularly productive by then, but I'm not sure this is a good argument, since the reason we have 兒 as a separate character is presumably because it's originally syllabic and only became subsyllabic by phonological reduction ..."
visualnovels,fotpltl,t3_g9db3t,1588061624.0,"In some of my research areas (Chinese linguistics and Tibeto-Burman linguistics) there's a fair amount of papers and dictionaries in Japanese. There are some Japanese researchers like Nishi Yoshio who would publish only or primarily in Japanese. It's my main reason for learning Japanese, ~~and I get an extra excuse to read VNs for it so I don't mind it at all~~."
linguistics,fothc6d,t3_g90bpv,1588053947.0,Is there any work on the semantics and discourse function of English *in the first place*?
linguistics,fotfp0g,t3_g97ck7,1588052581.0,"留守 (Chinese liúshǒu / Japanese るす). In Chinese if you 留守, you are staying behind while other people are away. In Japanese, it means you are away."
linguistics,fotfi4z,t3_g9cd0h,1588052425.0,Could you be a bit more specific on what you are trying to achieve? Quantitative / qualitative approaches means pretty much the entirety of the literature on linguistic methodology ...
linguistics,fotfatf,t3_g9a90i,1588052256.0,"Quick note about your images, I can't really see them with the black background on Chrome. I tried downloading them and reading them on the Windows photo reader, but I couldn't read them easily with a white background either. If they're important, could you reupload them with a white background instead of transparent?

Secondly, what do you mean by 'difference in the use'? Do you mean whether there's a difference in the probability that someone will choose a modal verb over a mood adjunct in each of the cases? Whether, within modal verbs and mood adjuncts, low probability is more likely than high probability, low usuality is higher than low usuality, etc? I think you need to be a bit more specific. I don't mean put any blame on you - I frequented r/askstatistics for a while and was frustrated by a lot of questions that are way vaguer than this - but I'm still not exactly sure what you're trying to ask. It's important that we know what exactly you're trying to do, or we may make wrong recommendations.

Finally ... please don't use a t-test for this :P I know some corpus linguistics textbooks recommend it, but this kind of 0/1 data really is not what the t-test is used for."
linguistics,fot02x1,t3_g9e421,1588041686.0,"Firstly, it's not really accurate to say that the Tibeto-Burman languages are relatively agglutinative. The Tibeto-Burman languages exhibit a huge amount of internal variation; there are some branches (e.g. Naic) that are isolating like Chinese, there are branches (e.g. Bodic) that are relatively agglutinative, and there are some branches (e.g. Kiranti) that are pretty much polysynthetic. (In fact, excluding Chinese from Tibeto-Burman is already a controversial position; there are many linguists who do not believe in the binary branching of Chinese and Tibeto-Burman and would use 'Tibeto-Burman' as a label for the top-level family, at least before Trans-Himalayan was introduced.)

What their common ancestor was like a bit of a minefield ... In fact, whether the common ancestor was pronominalised (i.e. whether it had person indexing) is probably one of the most contentious issues in linguistics: There are people like LaPolla and Thurgood who believe that it did not and that person indexing was an innovation, and then there are people who believe that it was Chinese (and Tibetan and Burmese) that lost person indexing.

What we *can* be sure of, though I know this doesn't really answer your question directly, was that Old Chinese was not as isolating as you might think from reading classical texts, because there was a fair bit of morphology not shown by the hanzi. This morphology was largely derivational; see Baxter and Sagart (1998) for an overview. I've heard of suspicions from dialect data that Old Chinese might have had some inflectional morphology, but I have never been able to find the papers concerning that.

Baxter, William H. & Laurent Sagart. 1998. Word formation in old Chinese. New Approaches to Chinese Word Formation: Morphology, phonology and the lexicon in modern and ancient Chinese. Mouton de Gruyter Berlin 35–76."
badlinguistics,fosu4nv,t3_g99oco,1588038094.0,"> languages don't borrow grammar

This is from a relatively goodling comment, but it's still wrong. Contact can definitely cause syntactic change. For example, the use of 自 as the possessor in noun phrases in Middle Chinese is a Sanskrit influence.

Also:

> ""the Japanese language is mostly copied/altered Chinese"" isn't a simplification, it's wrong. They aren't even in the same language family. It's about as wrong as saying ""the English language is mostly copied/altered French"". They're both in different language families, have very different grammar, and their modern forms are nothing like when the languages were sharing features the most.

They seem to be suggesting that English and French belong in different language families and have very different grammar. English and French belong in the same language family and the grammars aren't as radically different as Chinese and Japanese are."
badlinguistics,fostsex,t1_fosbfj2,1588037892.0,"While it's funny the way you say it, the sad thing is I'm 101% sure there are people out there who will say this with a straight face."
visualnovels,foq7djk,t3_g8f1vz,1587985615.0,"Some VNs, although ostensibly containing choices, are virtually linear in that (roughly) each ending leads to the unlocking of very few, usually only one, choice, which can be very far away from the ending that you got. In such games, having a flowchart so that you can see where a new branch appeared after each ending can be useful. Some recent examples are Tsukikage no Simulacre and Raging Loop."
asklinguistics,foq73yw,t3_g8x80m,1587985355.0,"> sharing language is just another way to show respect, like mimicking body language can be

A problem is that sharing language does not *always* show respect. When white people appropriate AAVE features, sometimes the features gain new indexical meanings in ways that reflect problematic ideologies. For example, AAVE features that are appropriated are often used by white speakers in humorous contexts, which reflects a problematic link between blackness and humour."
visualnovels,fomuuqb,t3_g8ch6h,1587904559.0,"I haven't read ever17, but I feel that in general, what get adapted to anime don't really correspond very well to our perceptions of which works are better and/or more suited for adaptions. I was pretty surprised that Munou na Nana is getting an adaption before G-sen and Sharin no Kuni (for those who didn't know, this came out a couple weeks ago), considering that MnN, at the offset, is a collection of good but relatively loosely connected chapters and doesn't really start its main plotline until 20 chapters later or so, whereas G-sen and SnK start out much stronger by emphasising both the main plot elements *and* the battles of wit from the beginning. I suspect the reason is just that MnN is a manga and thus has a bigger readerhood than G-sen and SnK."
linguistics,fom4pem,t1_fom4j4d,1587878251.0,Thanks!
linguistics,foj8vbp,t1_foj88rg,1587812976.0,"自 in Middle Chinese. It developed more discoursey meanings that I think sometimes overlap quite a bit with やっぱり, though of course it still retained reflexive meaning."
linguistics,foj7ic2,t3_g4seyo,1587811460.0,"Does anyone know of literature on the historical development of Japanese やっぱり, like which sense came first and how the other senses were derived? I'm looking at a morpheme that has a very similar kind of polysemy, so this would be an important reference point. Thanks!"
HongKong,foj6gss,t1_foiwfny,1587810283.0,"It's not uncommon for doujin VNs to be unvoiced, unfortunately. Even Higurashi was originally unvoiced."
HongKong,foj6gdm,t3_g7apcn,1587810270.0,"In case anyone's interested, there's another [HK film-themed VN](https://www.rpgdl.org/rsl/en.html), which is an otomege and is also available on steam."
linguistics,foiywdp,t1_fogz38r,1587801852.0,"> It seems to me that you're confused about what transitivity means, and what domain it applies to. Transitivity is a syntactic phenomenon, which is independent of other verbal properties like tense, aspect, mood, etc.

Um, but lexical aspect and realis are two of the properties in Hopper and Thompson (1980). You probably disagree with their terminological choice, and you're probably right - it does cause some confusion - but I think we should at least let OP know this, considering how influential H&T have been on the literature. If OP decides to look up DeLancey's early work on ergativity in Tibetan, for example, they would definitely come across transitivity that depends on TAM.

> You cannot leave out a proposition, so I assume you meant 'preposition'. Prepositions and adverbs have nothing to do with transitivity.

I think I can see what they have in mind though. If you call Japanese particles postpositions, for example, then surely the presence of the accusative *wo* marker, for example, can be relevant to transitivity (e.g. 勉強する 'study do' would seem intransitive vs 勉強をする 'study ACC do' which would seem transitive)."
linguistics,foixgz0,t3_g6oibw,1587800357.0,"It is useful to define two different notions of transitivity. One is the *semantic* notion of transitivity, which is first proposed by Hopper and Thompson (1980), probably the most influential modern paper on transitivity (as well as one of the most important papers in syntax). Hopper and Thompson suggest a number of semantic features that together form the notion of transitivity:

Property | High-transitivity | Low-transitivity
---|---|----
Participants | >1| 1
Kinesis | action | non-action
Aspect | telic | non-telic
Punctuality | punctual | non-punctual
Volitionality | volitional | non-volitional
Affirmation | affirmative | negative
Mode | realis | irrealis
Agency | A high in potency | A low in potency
Affectedness of O | O totally affected | O not affected
Individuation of O | O highly indiviudated | O not individuated

The main idea that is frequently cited is that, roughly, these properties 'go together' in languages. You can see the original paper for the precise formulation, but by way of example, following Hopper and Thompson, we would expect that in a language, if one verb is punctual and another verb is  non-punctual, then if both verbs are strict about the number of participants they take and the numbers are different, we would expect the punctual verb to take >1 participant and the non-punctual verb to take one participant, never the other way around. For example, in French, *Je m'endors* (I go to sleep), with a subject and a reflexive object, is punctual, whereas *Je dors* (I sleep), with only a subject, is non-punctual

The other notion (or, more accurately, *class of notions*) of transitivity is morphosyntactic transitivity. Morphosyntactic transitivity is to semantic transitivity as, say, time is to tense. Every language expresses time in some way, but not every language has things like past tense. Similarly, although the semantic distinctions like those pointed out by Hopper and Thompson are relevant to every language, this does not mean that every language has to grammaticalise transitivity to the same extent. Some typical examples of ways that transitivity may arise are core argument marking and person indexing on the verb. For example, if there's a language that always marks Direct Object arguments with a case marker, the Accusative marker is a morphosyntactic manifestation of transitivity.

Moreover, the definition of morphosyntactic transitivity varies greatly from language to language, and must be motivated on purely language-internal terms. LaPolla (2011) gives the examples of Rawang and Qiang, and shows that very different criteria should be used to distinguish transitive from intransitive clauses. In some languages, such as Mongsen Ao (Coupe 2011), transitivity is only marginally relevant to a small part of the language (a small number of constructions), and in some Tibeto-Burman languages, it may not be useful notion at all - see references at the end of LaPolla, Kratochvil and Coupe (2011).

Coupe, Alexander. 2011. Pragmatic foundations of transitivity in Ao. *Studies in Language* 35(3). 492–522. https://doi.org10.1075/sl.35.3.01cou.

Hopper, Paul J. & Sandra A. Thompson. 1980. Transitivity in Grammar and Discourse. *Language* 56(2). 251. https://doi.org10.2307/413757.

LaPolla, Randy J. 2011. On transitivity in two Tibeto-Burman languages. *Studies in Language* 35(3). 636–649. https://doi.org10.1075/sl.35.3.05lap.

LaPolla, Randy J., František Kratochvíl & Alexander R. Coupe. 2011. On transitivity. *Studies in Language.*  35(3). 469–492."
visualnovels,fohccn3,t1_foh5huk,1587763593.0,"Just a heads up, the rest of ISLAND is ... nothing like what you've read so far."
asklinguistics,fof8cut,t1_foelvqj,1587729389.0,">  I don't know what the value is on finding ""one word"", which is why I'm offering verbal compounds.

I'm all for rejecting crosslinguistic notions of 'a word', but I don't think anyone would consider the phrases you give to be compounds. Only the first one seems to be semantically what the OP is looking for, and it has all the formal trappings of any other verb + object phrase and is transparently compositional. I don't really see how it's more than a collocation."
visualnovels,foexf4w,t1_foewh7y,1587718187.0,"Hmm thanks! Doko he iku no, ano hi sounds pretty interesting, I might check that out tomorrow. Wonder why I've never heard of that."
visualnovels,foewcdq,t3_g73ez5,1587717060.0,So is this like Netflix but for VNs? Or do you have to show you own the VN in some way before you can play it there (in which case this sounds really expensive for the purpose)? It seems to be like a Netflix from the frontpage description but I'm not 100% sure.
visualnovels,foerci5,t1_fo9nomq,1587712136.0,"> I mostly use ""mah"" instead of ""but"" or ""although"", but it kind of works in my language so it usually passes.

It sorta works in my language too but I think it's the *frequency* at which you do it that makes it obvious you've been affected by VNs / other Japanese media lol. When I read translated VNs there's a lot of turns of phrase that are pretty rare outside of works translated from Japanese and I'd probably snicker if anyone uses those more than once in a while.

> bow slightly in certain situations, pat people on the head

Are you sure these are VN influences? I have done those since I was a kid and long before I consumed Japanese media as much as I do now lol."
visualnovels,foeqz85,t3_g6ws8f,1587711791.0,"I've been intending to start Japanese for a while, because I have non-entertainment reasons for it. (German is the probably the most useful for me to start in the long run but Japanese has the edge in the short run.) I started a couple months before quarantine began, but quarantine definitely helped to give me more time, especially as I'm learning another language simultaneously. I don't do that much VN reading for fun these days so it's good to have language learning as an excuse to read VNs anyway (even though it means straying away from my usual diet of mainly horror VNs with some thriller / mystery, because those tend not to be as easy reads).

I think I'm proceeding much faster in Japanese than in the other language I'm currently learning (which I started earlier), even faster in fact than when I started my fourth language when I was 10 (it took around eight years of studying that before I read my first book). I can read websites (~~mostly DLSite game descriptions~~) fairly comfortably now with Rikaikun turned on and I'm not really needing the translations in Go Go Nippon other than for sentences with a fairly large number of new vocab. My goal now with VNs is to get my reading speed for simple sentences to be as fast as possible so that I'm more comfortable reading with the longer and more complex sentences that I'll need to be able to decode. I don't want to start with complex sentences too early or I have a feeling it will be a chore to decode everything - and I will probably fall back on translating everything into my native language in my head first, which I did for a while with my fourth language and probably isn't an efficient way to read."
visualnovels,foepi3s,t1_fodl6nz,1587710446.0,"If you want Chinese translations (including fanpatches), just use vndb. It's very complete and I think there's only been one instance where I'm aware of a translation that exists but was not on vndb. You only need to browse Chinese websites if you're looking for good OCLVNs (vndb *can't* be relied on for that, unfortunately). For that I would suggest just searching for the word 国产 plus galgame  / 乙女游戏 / 耽美游戏 / 文字冒险游戏 on Baidu, and you should find a fair number of recommendations."
visualnovels,fodiuxw,t1_fodhlgm,1587685240.0,"Do you mean that they don't even have text on the screen, or simply don't have a dual language option (I'm guessing the latter)? For VNs as easy as Go Go Nippon, I don't think the dual language option would affect things that much, at least after the beginning, since I am not really using it much after Day 1, except for sentences with an exceptionally large amount of new vocab in the infodumps."
visualnovels,fodazhg,t1_fod8mqq,1587682420.0,"> want to actually learn Japanese

Or want to memorise vocab through reading VNs. I personally don't do that - we already have Memrise, Anki and Clozemaster for memorising vocabulary (and I don't know about other people but I spend a lot of time on these things). I'd prefer using VNs just for training reading speed. So I think it goes down to your learning style."
