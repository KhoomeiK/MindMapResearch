{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONvGwK4EKFVkGgIZFwY8sA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhoomeiK/MindMapResearch/blob/master/HAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX-Fo7SmKR8j",
        "colab_type": "text"
      },
      "source": [
        "## DATA PREP STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpO2AIcKU68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download dataset and labels\n",
        "! pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# downloaded1 = drive.CreateFile({'id': '1oZb283stxpZn8Dn8i8e2Vh6P8d6Voj4Y'}) \n",
        "# downloaded1.GetContentFile('dataset.zip')  \n",
        "\n",
        "downloaded2 = drive.CreateFile({'id': '1-1nQU2lUwBnEyNot0EeVK72X92bdqVAu'}) \n",
        "downloaded2.GetContentFile('labels.pkl')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1-XYU2MCNbhS8ir_7ToC5DvrUMsQy9-9E'}) \n",
        "downloaded.GetContentFile('embeddings.zip')\n",
        "\n",
        "# ! unzip dataset.zip\n",
        "# ! rm -rf cse198f_shiv/data\n",
        "# ! rm -rf cse198f_shiv/diagnostics\n",
        "# ! rm -rf cse198f_shiv/models\n",
        "# ! rm cse198f_shiv/vectors.py\n",
        "# ! ls cse198f_shiv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtLDPaK8Lx1F",
        "colab_type": "code",
        "outputId": "90b72bdf-8743-4377-9a7a-ae89ec2ba379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# read dataset into memory\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "mypath = 'cse198f_shiv'\n",
        "csvs = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(len(csvs))\n",
        "\n",
        "data = []\n",
        "names = []\n",
        "for csv in csvs:\n",
        "    if csv[-4:] == '.csv':\n",
        "        try:\n",
        "            data.append(pd.read_csv(join(mypath, csv), encoding='CP1252'))\n",
        "            names.append(csv[:-4])\n",
        "        except:\n",
        "            try:\n",
        "                data.append(pd.read_csv(join(mypath, csv), encoding='UTF8'))\n",
        "                names.append(csv[:-4])\n",
        "            except:\n",
        "                continue\n",
        "print(len(data))\n",
        "\n",
        "# pd.reset_option('all')\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2052\n",
            "1980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwXvyU5BKmFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # download embedding tools\n",
        "# ! ls *\n",
        "# ! mkdir fastText\n",
        "# ! curl https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip > fastText/crawl-300d-2M.vec.zip\n",
        "# ! unzip fastText/crawl-300d-2M.vec.zip -d fastText/\n",
        "# ! mkdir encoder\n",
        "# ! curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n",
        "# ! curl https://raw.githubusercontent.com/facebookresearch/InferSent/master/models.py > models.py\n",
        "# ! mkdir embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvD3ckkkZXRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate embeddings of dataset\n",
        "import torch, os\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from absl import logging\n",
        "from models import InferSent\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "MODEL_PATH = 'encoder/infersent2.pkl'\n",
        "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
        "\n",
        "def load_infersent_model(model_path=MODEL_PATH, word_embeddings_path=W2V_PATH):\n",
        "\tparams_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048, 'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
        "\tinfersent = InferSent(params_model).cuda()\n",
        "\tinfersent.load_state_dict(torch.load(model_path))\n",
        "\tinfersent.set_w2v_path(word_embeddings_path)\n",
        "\tinfersent.build_vocab_k_words(K=100000)\n",
        "\treturn infersent\n",
        "\n",
        "def get_infersent_vectors(sentences, model):\n",
        "\treturn model.encode(sentences, tokenize=False, verbose=False)\n",
        "\n",
        "def get_user_data_embeddings(comments, model):\n",
        "\t# model = load_infersent_model()\n",
        "\tembedding = get_infersent_vectors(comments, model)\n",
        "\treturn embedding\n",
        "\n",
        "dataEmbeddings = []\n",
        "model = load_infersent_model()\n",
        "\n",
        "start = time.time()\n",
        "for i, name in enumerate(names):\n",
        "\tcomments = list(data[i]['text']) if 'text' in data[i] else []\n",
        "\tif len(comments) >= 1:\n",
        "\t\tprint(i, name)\n",
        "\t\ttry:\n",
        "\t\t\tembeddings = get_user_data_embeddings(data[i]['text'], model)\n",
        "\t\t\tprint(len(embeddings), 'comments')\n",
        "\t\t\tdataEmbeddings.append(embeddings)\n",
        "\t\t\twith open('embeddings/%s.pkl' % name, 'wb') as pkl:\n",
        "\t\t\t\tpickle.dump(embeddings, pkl)\n",
        "\t\texcept:\n",
        "\t\t\tprint('ERROR')\n",
        "\n",
        "print(time.time() - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2TyG1kaKWcq",
        "colab_type": "text"
      },
      "source": [
        "## MODEL RUN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjnF_q1FqaE",
        "colab_type": "code",
        "outputId": "892ebfbc-e595-4924-8d67-c86e47f53aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# load labels and user embeddings and create Users data obj\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from csv import reader\n",
        "import pickle\n",
        "from os import listdir\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Users(Dataset):\n",
        "    def __init__(self, embedPath, labelPath, split): \n",
        "        self.users, self.labels = [], []\n",
        "        users = {}\n",
        "        labels = pickle.load(open(labelPath, 'rb')) # { username: [ depressionPercent, vaderScore ] }\n",
        "        fileList = listdir(embedPath)\n",
        "\n",
        "        if type(split) == float:\n",
        "            userList = random.sample(fileList, int(len(fileList) * split))\n",
        "            for user in userList: # must download and unzip embeddings.zip first\n",
        "                users[user[:-4]] = pickle.load(open('%s/%s' % (embedPath, user), 'rb'))\n",
        "            \n",
        "            intersection = list(set(users.keys()).intersection(set(labels.keys())))\n",
        "            for i in intersection:\n",
        "                userTensor = torch.tensor(users[i])\n",
        "                if list(userTensor.shape)[0] != 1: # exclude single comment users\n",
        "                    self.users.append(userTensor)\n",
        "                    self.labels.append(torch.tensor(labels[i]))\n",
        "\n",
        "            self.usernames = users.keys()\n",
        "    \n",
        "        elif type(split) == Users:\n",
        "            for user in fileList: # must download and unzip embeddings.zip first\n",
        "                if user[:-4] not in split.usernames:\n",
        "                    users[user[:-4]] = pickle.load(open('%s/%s' % (embedPath, user), 'rb'))\n",
        "            \n",
        "            intersection = list(set(users.keys()).intersection(set(labels.keys())))\n",
        "            for i in intersection:\n",
        "                userTensor = torch.tensor(users[i])\n",
        "                if list(userTensor.shape)[0] != 1: # exclude single comment users\n",
        "                    self.users.append(userTensor)\n",
        "                    self.labels.append(torch.tensor(labels[i]))\n",
        "        \n",
        "        else:\n",
        "            print('ERROR')\n",
        "\n",
        "        print(len(self), self[0])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.users[i], self.labels[i][0] # remove [0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.users) == len(self.labels)\n",
        "        return len(self.users)\n",
        "\n",
        "# ! unzip embeddings.zip\n",
        "train = Users('embeddings', 'labels.pkl', 0.8)\n",
        "test = Users('embeddings', 'labels.pkl', train)\n",
        "train, test = DataLoader(train), DataLoader(test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1387 (tensor([[ 7.4689e-03, -1.3480e-01, -4.2769e-02,  ..., -6.6668e-02,\n",
            "         -4.1580e-02, -1.9568e-02],\n",
            "        [ 7.4689e-03, -4.9213e-02, -7.3091e-02,  ...,  3.4554e-02,\n",
            "         -4.8900e-02, -1.5373e-02],\n",
            "        [ 7.4689e-03, -2.1242e-02, -7.1628e-02,  ..., -8.6076e-03,\n",
            "          7.6879e-03, -4.9480e-02],\n",
            "        ...,\n",
            "        [ 7.4689e-03,  7.0529e-02,  1.0929e-01,  ...,  5.5297e-02,\n",
            "          3.7981e-02, -6.8325e-03],\n",
            "        [ 7.4689e-03, -1.5866e-02, -8.3607e-05,  ..., -2.0220e-02,\n",
            "          1.3644e-02, -1.8471e-02],\n",
            "        [ 7.4689e-03, -7.7452e-03,  5.7486e-02,  ...,  2.2026e-02,\n",
            "          8.7726e-02, -1.9869e-02]]), tensor(0.0047))\n",
            "346 (tensor([[ 0.0075, -0.0341,  0.0681,  ...,  0.0356,  0.0389, -0.0088],\n",
            "        [ 0.0075, -0.0313,  0.1253,  ...,  0.0469,  0.0337,  0.0126],\n",
            "        [ 0.0075, -0.0559, -0.0130,  ...,  0.0399,  0.0449, -0.0196],\n",
            "        ...,\n",
            "        [ 0.0075,  0.0356,  0.0487,  ...,  0.0215,  0.0350, -0.0248],\n",
            "        [ 0.0075, -0.0140, -0.0516,  ...,  0.0033, -0.0551, -0.0055],\n",
            "        [ 0.0075, -0.0241,  0.0130,  ...,  0.0426,  0.0571, -0.0079]]), tensor(0.0046))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPOBU7jhQ5P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matrix_mul(input, weight, bias=False):\n",
        "    feature_list = []\n",
        "    _input = input.squeeze(0)\n",
        "    for feature in _input:\n",
        "        feature = feature.unsqueeze(1).reshape(1, 300)\n",
        "        f = torch.mm(feature, weight)\n",
        "        if isinstance(bias, torch.nn.parameter.Parameter):\n",
        "            feature = feature + bias.expand(feature.size()[0], bias.size()[1])\n",
        "        feature = torch.tanh(feature).unsqueeze(0)\n",
        "        feature_list.append(feature)\n",
        "\n",
        "    return torch.cat(feature_list, 0).squeeze(1)\n",
        "\n",
        "def element_wise_mul(input1, input2):\n",
        "    _input1 = input1.squeeze(0)\n",
        "    feature_list = []\n",
        "    for feature_1, feature_2 in zip(_input1, input2):\n",
        "        feature = feature_1 * feature_2\n",
        "        feature_list.append(feature.unsqueeze(0))\n",
        "\n",
        "    output = torch.cat(feature_list, 0)\n",
        "    return torch.sum(output, 0).unsqueeze(0)\n",
        "\n",
        "class HAN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size=8,\n",
        "        embedding_dimension=4096, # from glove to infersent?\n",
        "        hidden_size=150, \n",
        "        n_layers=1, # multiple?\n",
        "    ):\n",
        "        super(HAN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.sent_weight = nn.Parameter(torch.randn(2 * hidden_size, 2 * hidden_size))\n",
        "        self.sent_bias = nn.Parameter(torch.randn(1, 2 * hidden_size))\n",
        "        self.context_weight = nn.Parameter(torch.randn(2 * hidden_size, 1))\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dimension, hidden_size, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, 1)\n",
        "        # self.sent_softmax = nn.Softmax()\n",
        "        # self.fc_softmax = nn.Softmax()\n",
        "        self._create_weights(mean=0.0, std=0.05)\n",
        "\n",
        "    def _create_weights(self, mean=0.0, std=0.05):\n",
        "        self.sent_weight.data.normal_(mean, std)\n",
        "        self.sent_bias.data.normal_(mean, std)\n",
        "        self.context_weight.data.normal_(mean, std)\n",
        "\n",
        "    def forward(self, user):\n",
        "        f_output, h_output = self.gru(user)\n",
        "        output = matrix_mul(f_output, self.sent_weight, self.sent_bias)\n",
        "        output = matrix_mul(output, self.context_weight).permute(1, 0)\n",
        "        output = F.softmax(output)\n",
        "        output = element_wise_mul(f_output, output.permute(1, 0)).squeeze(0)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output #, h_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE5ZZhfhTk_I",
        "colab_type": "code",
        "outputId": "b6a4c8cc-5b0d-46d8-fc42-9143adf77f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model = HAN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "train_losses, losses = [], []\n",
        "model.train()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total = 0\n",
        "    for X, Y in train:\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += 1\n",
        "        losses.append(loss.item())\n",
        "    \n",
        "    epoch_loss = sum(losses) / total\n",
        "    print(epoch_loss)\n",
        "    train_losses.append(epoch_loss)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0006346032317407751\n",
            "0.0006575405189248062\n",
            "0.0006616856136274855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5BcxiHTZCdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2b3d29cf-d3c1-4d4c-e898-39e66f2518d6"
      },
      "source": [
        "test_losses, losses = [], []\n",
        "torch.no_grad()\n",
        "total = 0\n",
        "\n",
        "for X, Y in test:\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X)\n",
        "    loss = criterion(pred, Y)\n",
        "    # print('pred', pred.item())\n",
        "    # print('targ', Y.item())\n",
        "    # print('loss', loss.item())\n",
        "\n",
        "    total += 1\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # if total == 50:\n",
        "    #     break\n",
        "\n",
        "epoch_loss = sum(losses) / total\n",
        "print(epoch_loss)\n",
        "test_losses.append(epoch_loss)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.271625992840745e-06\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}