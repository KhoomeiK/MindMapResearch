{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiO01Lrr5WegylSczt7MGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhoomeiK/MindMapResearch/blob/master/HAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX-Fo7SmKR8j",
        "colab_type": "text"
      },
      "source": [
        "## DATA PREP STUFF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpO2AIcKU68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download dataset and labels\n",
        "! pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded2 = drive.CreateFile({'id': '1WYdQ6xeZ8GaZZftXTnbtzEOP0LvWnG3W'}) \n",
        "downloaded2.GetContentFile('labels.pkl')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1BqSv5mgxsyP5rhMoAAKFyvPtAH8XLcO6'}) \n",
        "downloaded.GetContentFile('embeddings.zip')\n",
        "\n",
        "! unzip embeddings.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtLDPaK8Lx1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read dataset into memory\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "mypath = 'cse198f_shiv'\n",
        "csvs = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(len(csvs))\n",
        "\n",
        "data = []\n",
        "names = []\n",
        "for csv in csvs:\n",
        "    if csv[-4:] == '.csv':\n",
        "        try:\n",
        "            data.append(pd.read_csv(join(mypath, csv), encoding='CP1252'))\n",
        "            names.append(csv[:-4])\n",
        "        except:\n",
        "            try:\n",
        "                data.append(pd.read_csv(join(mypath, csv), encoding='UTF8'))\n",
        "                names.append(csv[:-4])\n",
        "            except:\n",
        "                continue\n",
        "print(len(data))\n",
        "\n",
        "# pd.reset_option('all')\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.width', None)\n",
        "# pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwXvyU5BKmFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # download embedding tools\n",
        "# ! ls *\n",
        "# ! mkdir fastText\n",
        "# ! curl https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip > fastText/crawl-300d-2M.vec.zip\n",
        "# ! unzip fastText/crawl-300d-2M.vec.zip -d fastText/\n",
        "# ! mkdir encoder\n",
        "# ! curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n",
        "# ! curl https://raw.githubusercontent.com/facebookresearch/InferSent/master/models.py > models.py\n",
        "# ! mkdir embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvD3ckkkZXRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate embeddings of dataset\n",
        "import torch, os\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from absl import logging\n",
        "from models import InferSent\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "MODEL_PATH = 'encoder/infersent2.pkl'\n",
        "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
        "\n",
        "def load_infersent_model(model_path=MODEL_PATH, word_embeddings_path=W2V_PATH):\n",
        "\tparams_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048, 'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
        "\tinfersent = InferSent(params_model).cuda()\n",
        "\tinfersent.load_state_dict(torch.load(model_path))\n",
        "\tinfersent.set_w2v_path(word_embeddings_path)\n",
        "\tinfersent.build_vocab_k_words(K=100000)\n",
        "\treturn infersent\n",
        "\n",
        "def get_infersent_vectors(sentences, model):\n",
        "\treturn model.encode(sentences, tokenize=False, verbose=False)\n",
        "\n",
        "def get_user_data_embeddings(comments, model):\n",
        "\t# model = load_infersent_model()\n",
        "\tembedding = get_infersent_vectors(comments, model)\n",
        "\treturn embedding\n",
        "\n",
        "dataEmbeddings = []\n",
        "model = load_infersent_model()\n",
        "\n",
        "start = time.time()\n",
        "for i, name in enumerate(names):\n",
        "\tcomments = list(data[i]['text']) if 'text' in data[i] else []\n",
        "\tif len(comments) >= 1:\n",
        "\t\tprint(i, name)\n",
        "\t\ttry:\n",
        "\t\t\tembeddings = get_user_data_embeddings(data[i]['text'], model)\n",
        "\t\t\tprint(len(embeddings), 'comments')\n",
        "\t\t\tdataEmbeddings.append(embeddings)\n",
        "\t\t\twith open('embeddings/%s.pkl' % name, 'wb') as pkl:\n",
        "\t\t\t\tpickle.dump(embeddings, pkl)\n",
        "\t\texcept:\n",
        "\t\t\tprint('ERROR')\n",
        "\n",
        "print(time.time() - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2TyG1kaKWcq",
        "colab_type": "text"
      },
      "source": [
        "## MODEL RUN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjnF_q1FqaE",
        "colab_type": "code",
        "outputId": "3c84c1b0-4da1-4a25-d372-b4b576eb3c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# load labels and user embeddings and create Users data obj\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from csv import reader\n",
        "import pickle\n",
        "from os import listdir\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Users(Dataset):\n",
        "    def __init__(self, embedPath, labelPath, split): \n",
        "        self.users, self.labels = [], []\n",
        "        users = {}\n",
        "        labels = pickle.load(open(labelPath, 'rb')) # { username: [ depressionPercent, vaderScore ] }\n",
        "        fileList = listdir(embedPath)\n",
        "\n",
        "        if type(split) == float:\n",
        "            userList = random.sample(fileList, int(len(fileList) * split))\n",
        "            for user in userList: # must download and unzip embeddings.zip first\n",
        "                users[user[:-4]] = pickle.load(open('%s/%s' % (embedPath, user), 'rb'))\n",
        "            self.usernames = users.keys()\n",
        "    \n",
        "        elif type(split) == Users:\n",
        "            for user in fileList:\n",
        "                if user[:-4] not in split.usernames:\n",
        "                    users[user[:-4]] = pickle.load(open('%s/%s' % (embedPath, user), 'rb'))\n",
        "        \n",
        "        intersection = list(set(users.keys()).intersection(set(labels.keys())))\n",
        "        for i in intersection:\n",
        "            userTensor = torch.tensor([users[i]])\n",
        "            if list(userTensor.shape)[1] != 1: # exclude single comment users\n",
        "                self.users.append(userTensor)\n",
        "                self.labels.append(torch.tensor([labels[i]]))\n",
        "\n",
        "        print(len(self), self[0])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.users[i], self.labels[i] # remove [0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.users) == len(self.labels)\n",
        "        return len(self.users)\n",
        "\n",
        "# def my_collate(batch):\n",
        "#     data = [item[0] for item in batch]\n",
        "#     target = [item[1] for item in batch]\n",
        "#     target = torch.Tensor(target)\n",
        "#     return [data, target]\n",
        "\n",
        "train = Users('user_subset', 'labels.pkl', 0.8)\n",
        "test = Users('user_subset', 'labels.pkl', train)\n",
        "dataloader_params = {'shuffle': True}\n",
        "# dataloader_params = {'batch_size': 4, 'shuffle': True, 'collate_fn': my_collate}\n",
        "# train, test = DataLoader(train, **dataloader_params), DataLoader(test, **dataloader_params)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4283 (tensor([[[ 0.0075, -0.0305,  0.0211,  ..., -0.0712, -0.0425, -0.0419],\n",
            "         [ 0.0075,  0.0172,  0.0182,  ...,  0.0570, -0.0313,  0.0316],\n",
            "         [ 0.0075,  0.0785, -0.0169,  ...,  0.0286, -0.0207, -0.0089],\n",
            "         ...,\n",
            "         [ 0.0075, -0.0349,  0.0532,  ...,  0.0260,  0.0789,  0.0068],\n",
            "         [ 0.0075, -0.0679,  0.0344,  ..., -0.0303, -0.0051, -0.0049],\n",
            "         [ 0.0075,  0.0095,  0.0598,  ...,  0.0493,  0.0140,  0.0096]]]), tensor([ 2.9258e+00, -2.6232e-06]))\n",
            "1073 (tensor([[[ 0.0075,  0.0108,  0.1532,  ...,  0.1020,  0.0197, -0.0015],\n",
            "         [ 0.0075,  0.0294,  0.0614,  ...,  0.0334,  0.0144,  0.0117],\n",
            "         [ 0.0075,  0.1654,  0.0547,  ...,  0.0074,  0.0391, -0.0292],\n",
            "         ...,\n",
            "         [ 0.0075,  0.1244,  0.1437,  ...,  0.0627,  0.0317,  0.0030],\n",
            "         [ 0.0075,  0.0269,  0.0773,  ...,  0.0355,  0.0313,  0.0272],\n",
            "         [ 0.0075, -0.0335,  0.0611,  ...,  0.0192, -0.0057,  0.0158]]]), tensor([3.0937e+00, 5.7340e-06]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPOBU7jhQ5P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matrix_mul(input, weight, bias=False):\n",
        "    feature_list = []\n",
        "    _input = input.squeeze(0)\n",
        "    for feature in _input:\n",
        "        feature = feature.unsqueeze(1).reshape(1, 300)\n",
        "        feature = torch.mm(feature, weight)\n",
        "        if isinstance(bias, torch.nn.parameter.Parameter):\n",
        "            feature = feature + bias.expand(feature.size()[0], bias.size()[1])\n",
        "        feature = torch.tanh(feature)#.unsqueeze(0) ?\n",
        "        feature_list.append(feature)\n",
        "\n",
        "    return torch.cat(feature_list, 0)#.squeeze(1) ?\n",
        "\n",
        "def element_wise_mul(input1, input2):\n",
        "    _input1 = input1.squeeze(0)\n",
        "    feature_list = []\n",
        "    for feature_1, feature_2 in zip(_input1, input2):\n",
        "        feature = feature_1 * feature_2\n",
        "        feature_list.append(feature.unsqueeze(0))\n",
        "\n",
        "    output = torch.cat(feature_list, 0)\n",
        "    return torch.sum(output, 0).unsqueeze(0)\n",
        "\n",
        "class AN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size=4,\n",
        "        embedding_dimension=4096, # from glove to infersent?\n",
        "        hidden_size=150, \n",
        "        n_layers=1, # multiple?\n",
        "    ):\n",
        "        super(AN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.sent_weight = nn.Parameter(torch.randn(2 * hidden_size, 2 * hidden_size))\n",
        "        self.sent_bias = nn.Parameter(torch.randn(1, 2 * hidden_size))\n",
        "        self.context_weight = nn.Parameter(torch.randn(2 * hidden_size, 1))\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dimension, hidden_size, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, 1) \n",
        "        self._create_weights(mean=0.005)\n",
        "\n",
        "    def _create_weights(self, mean=0.0, std=0.01):\n",
        "        self.sent_weight.data.normal_(mean, std)\n",
        "        self.sent_bias.data.normal_(mean, std)\n",
        "        self.context_weight.data.normal_(mean, std)\n",
        "\n",
        "    def forward(self, user):\n",
        "        f_output, h_output = self.gru(user)\n",
        "        output = matrix_mul(f_output, self.sent_weight, self.sent_bias)\n",
        "        output = matrix_mul(output, self.context_weight)#.permute(1, 0) ?\n",
        "        output = F.softmax(output)\n",
        "        output = element_wise_mul(f_output, output).squeeze(0) # '''output.permute(1, 0) ?'''\n",
        "        output = self.fc(output)\n",
        "        output = F.leaky_relu(output)\n",
        "\n",
        "        return output #, h_output\n",
        "\n",
        "class Simple(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size=4,\n",
        "        embedding_dimension=4096,\n",
        "        hidden_size=150, \n",
        "    ):\n",
        "        super(Simple, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dimension, hidden_size, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, 1) \n",
        "\n",
        "    def forward(self, user):\n",
        "        f_output, h_output = self.gru(user)\n",
        "        output = f_output[0][-1]\n",
        "        output = self.fc(output)\n",
        "        output = F.leaky_relu(output)\n",
        "\n",
        "        return output #, h_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE5ZZhfhTk_I",
        "colab_type": "code",
        "outputId": "46f28695-be7a-41b7-e5d9-b6e03fea7026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Simple().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()\n",
        "epochs = 10\n",
        "model.train()\n",
        "\n",
        "train_losses = []\n",
        "for epoch in range(epochs):\n",
        "    total = 0\n",
        "    losses = []\n",
        "    for X, Y in train:\n",
        "        # loss = 0\n",
        "        # X, Y = [x.unsqueeze(0).to(device) for x in X], [y.to(device) for y in Y]\n",
        "        # for x, y in zip(X, Y):\n",
        "        #     pred = model(x)\n",
        "        #     # print(pred, y)\n",
        "        #     if loss == 0:\n",
        "        #         loss = criterion(pred, y)\n",
        "        #     else:\n",
        "        #         loss += criterion(pred, y)\n",
        "        # loss /= 4\n",
        "        X, Y = X.to(device), Y[0].to(device)\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, Y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        total += 1\n",
        "\n",
        "        if total % 300 == 0:\n",
        "            print(pred.item(), Y.item(), loss.item())\n",
        "    \n",
        "    epoch_loss = sum(losses) / total\n",
        "    print(epoch, epoch_loss)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "print(train_losses)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.8068816661834717 3.0999999046325684 0.08591829985380173\n",
            "3.3222899436950684 3.0999999046325684 0.049412861466407776\n",
            "3.2013018131256104 3.090054988861084 0.012375855818390846\n",
            "2.99052095413208 3.0719640254974365 0.0066329739056527615\n",
            "2.9123282432556152 2.9069581031799316 2.8838403522968292e-05\n",
            "3.145559072494507 3.0999999046325684 0.0020756376907229424\n",
            "3.001337766647339 2.9319372177124023 0.00481643620878458\n",
            "3.1665351390838623 2.9213993549346924 0.06009155139327049\n",
            "3.0893356800079346 3.0712947845458984 0.00032547389855608344\n",
            "2.916375160217285 3.0999999046325684 0.0337180458009243\n",
            "2.9672510623931885 3.076308012008667 0.011893418617546558\n",
            "2.967952251434326 2.8958919048309326 0.005192693322896957\n",
            "2.8488476276397705 2.941307783126831 0.008548879995942116\n",
            "3.131556987762451 3.07671856880188 0.003007252234965563\n",
            "0 0.17648650353057424\n",
            "2.982814073562622 3.0999999046325684 0.013732519000768661\n",
            "2.9112727642059326 3.0999999046325684 0.03561793267726898\n",
            "3.092107057571411 3.090054988861084 4.210985935060307e-06\n",
            "3.000025510787964 3.0719640254974365 0.005175149999558926\n",
            "2.840083599090576 2.9069581031799316 0.004472199361771345\n",
            "3.0928115844726562 3.0999999046325684 5.167194831301458e-05\n",
            "3.0501694679260254 2.9319372177124023 0.013978864997625351\n",
            "3.0474822521209717 2.9213993549346924 0.01589689776301384\n",
            "3.1581172943115234 3.0712947845458984 0.0075381482020020485\n",
            "3.0027599334716797 3.0999999046325684 0.009455611929297447\n",
            "2.9477906227111816 3.076308012008667 0.01651671901345253\n",
            "2.9745073318481445 2.8958919048309326 0.0061803855933249\n",
            "2.916046619415283 2.941307783126831 0.0006381263956427574\n",
            "3.1132802963256836 3.07671856880188 0.0013367598876357079\n",
            "1 0.016059269521938473\n",
            "2.991853713989258 3.0999999046325684 0.011695598252117634\n",
            "2.931751251220703 3.0999999046325684 0.028307609260082245\n",
            "3.0891778469085693 3.090054988861084 7.693780048612098e-07\n",
            "2.9687659740448 3.0719640254974365 0.01064983755350113\n",
            "2.8571043014526367 2.9069581031799316 0.002485401462763548\n",
            "3.0841217041015625 3.0999999046325684 0.0002521172573324293\n",
            "3.0633137226104736 2.9319372177124023 0.017259785905480385\n",
            "3.033057451248169 2.9213993549346924 0.012467530556023121\n",
            "3.1347899436950684 3.0712947845458984 0.004031635355204344\n",
            "3.024035692214966 3.0999999046325684 0.005770561750978231\n",
            "2.9653518199920654 3.076308012008667 0.012311276979744434\n",
            "2.976731300354004 2.8958919048309326 0.006535008084028959\n",
            "2.9466171264648438 2.941307783126831 2.818912616930902e-05\n",
            "3.1039633750915527 3.07671856880188 0.0007422794587910175\n",
            "2 0.012797999221211779\n",
            "3.0141122341156006 3.0999999046325684 0.007376691792160273\n",
            "2.935558557510376 3.0999999046325684 0.027040956541895866\n",
            "3.096541166305542 3.090054988861084 4.207049641991034e-05\n",
            "2.9629950523376465 3.0719640254974365 0.011874237097799778\n",
            "2.8754138946533203 2.9069581031799316 0.0009950371459126472\n",
            "3.0790627002716064 3.0999999046325684 0.00043836652184836566\n",
            "3.074902296066284 2.9319372177124023 0.020439013838768005\n",
            "3.029860019683838 2.9213993549346924 0.011763716116547585\n",
            "3.110236644744873 3.0712947845458984 0.0015164684737101197\n",
            "3.038026809692383 3.0999999046325684 0.0038406644016504288\n",
            "2.9757885932922363 3.076308012008667 0.01010415330529213\n",
            "2.9807863235473633 2.8958919048309326 0.007207062561064959\n",
            "2.9629876613616943 2.941307783126831 0.0004700171120930463\n",
            "3.091456174850464 3.07671856880188 0.00021719702635891736\n",
            "3 0.010935028313758073\n",
            "3.0294249057769775 3.0999999046325684 0.004980830475687981\n",
            "2.9405577182769775 3.0999999046325684 0.025421811267733574\n",
            "3.101071834564209 3.090054988861084 0.00012137088924646378\n",
            "2.967022657394409 3.0719640254974365 0.01101269107311964\n",
            "2.8891336917877197 2.9069581031799316 0.00031770963687449694\n",
            "3.0759530067443848 3.0999999046325684 0.0005782532971352339\n",
            "3.081859588623047 2.9319372177124023 0.022476717829704285\n",
            "3.028554677963257 2.9213993549346924 0.01148226298391819\n",
            "3.0916244983673096 3.0712947845458984 0.0004132972680963576\n",
            "3.047156572341919 3.0999999046325684 0.0027924177702516317\n",
            "2.9807493686676025 3.076308012008667 0.009131453931331635\n",
            "2.986637592315674 2.8958919048309326 0.008234779350459576\n",
            "2.9741103649139404 2.941307783126831 0.0010760093573480844\n",
            "3.0800602436065674 3.07671856880188 1.1166790500283241e-05\n",
            "4 0.009677853684232643\n",
            "3.0386557579040527 3.0999999046325684 0.003763104323297739\n",
            "2.946887493133545 3.0999999046325684 0.02344341017305851\n",
            "3.1051995754241943 3.090054988861084 0.00022935849847272038\n",
            "2.9738857746124268 3.0719640254974365 0.009619343094527721\n",
            "2.8997511863708496 2.9069581031799316 5.1939648983534425e-05\n",
            "3.0746254920959473 3.0999999046325684 0.0006438608397729695\n",
            "3.0852880477905273 2.9319372177124023 0.023516476154327393\n",
            "3.027412176132202 2.9213993549346924 0.011238718405365944\n",
            "3.077035665512085 3.0712947845458984 3.2957716030068696e-05\n",
            "3.0535640716552734 3.0999999046325684 0.0021562865003943443\n",
            "2.9825291633605957 3.076308012008667 0.008794472552835941\n",
            "2.9932351112365723 2.8958919048309326 0.009475699625909328\n",
            "2.9820468425750732 2.941307783126831 0.0016596709610894322\n",
            "3.070899724960327 3.07671856880188 3.385894524399191e-05\n",
            "5 0.0087286130459065\n",
            "3.0440940856933594 3.0999999046325684 0.003125460585579276\n",
            "2.9533402919769287 3.0999999046325684 0.021509042009711266\n",
            "3.1100149154663086 3.090054988861084 0.0003983986680395901\n",
            "2.981137275695801 3.0719640254974365 0.008249498903751373\n",
            "2.909252166748047 2.9069581031799316 5.262727427179925e-06\n",
            "3.0751945972442627 3.0999999046325684 0.0006153032882139087\n",
            "3.086212158203125 2.9319372177124023 0.02380075678229332\n",
            "3.0262811183929443 2.9213993549346924 0.011000184342265129\n",
            "3.0647969245910645 3.0712947845458984 4.222218558425084e-05\n",
            "3.058725118637085 3.0999999046325684 0.0017036079661920667\n",
            "2.9829647541046143 3.076308012008667 0.00871296413242817\n",
            "2.999737501144409 2.8958919048309326 0.01078390795737505\n",
            "2.9872212409973145 2.941307783126831 0.002108045620843768\n",
            "3.0640578269958496 3.07671856880188 0.0001602943812031299\n",
            "6 0.007959463868778334\n",
            "3.0472934246063232 3.0999999046325684 0.0027779729571193457\n",
            "2.9594802856445312 3.0999999046325684 0.019745763391256332\n",
            "3.115638017654419 3.090054988861084 0.000654491363093257\n",
            "2.9884896278381348 3.0719640254974365 0.006967975292354822\n",
            "2.9182610511779785 2.9069581031799316 0.00012775663344655186\n",
            "3.0777642726898193 3.0999999046325684 0.0004944233223795891\n",
            "3.0852103233337402 2.9319372177124023 0.02349264547228813\n",
            "3.025373935699463 2.9213993549346924 0.010810713283717632\n",
            "3.0542147159576416 3.0712947845458984 0.00029172873473726213\n",
            "3.062775135040283 3.0999999046325684 0.0013856834266334772\n",
            "2.983258008956909 3.076308012008667 0.008658302947878838\n",
            "3.0052876472473145 2.8958919048309326 0.011967428028583527\n",
            "2.9899678230285645 2.941307783126831 0.0023677994031459093\n",
            "3.059490919113159 3.07671856880188 0.0002967919281218201\n",
            "7 0.0073084884051977505\n",
            "3.04899525642395 3.0999999046325684 0.002601474057883024\n",
            "2.9657816886901855 3.0999999046325684 0.01801452971994877\n",
            "3.1219966411590576 3.090054988861084 0.001020269119180739\n",
            "2.9959981441497803 3.0719640254974365 0.005770815070718527\n",
            "2.9269025325775146 2.9069581031799316 0.00039778026985004544\n",
            "3.0823917388916016 3.0999999046325684 0.0003100475005339831\n",
            "3.082890033721924 2.9319372177124023 0.022786753252148628\n",
            "3.024848699569702 2.9213993549346924 0.010701767168939114\n",
            "3.044832706451416 3.0712947845458984 0.0007002415950410068\n",
            "3.065793037414551 3.0999999046325684 0.001170109724625945\n",
            "2.98416805267334 3.076308012008667 0.008489771746098995\n",
            "3.0093743801116943 2.8958919048309326 0.012878271751105785\n",
            "2.9904961585998535 2.941307783126831 0.00241949618794024\n",
            "3.056952714920044 3.07671856880188 0.00039068897604011\n",
            "8 0.006741198009004452\n",
            "3.049558162689209 3.0999999046325684 0.002544369315728545\n",
            "2.972926139831543 3.0999999046325684 0.016147742047905922\n",
            "3.128986120223999 3.090054988861084 0.0015156329609453678\n",
            "3.0040040016174316 3.0719640254974365 0.004618564620614052\n",
            "2.934964895248413 2.9069581031799316 0.0007843804196454585\n",
            "3.0890190601348877 3.0999999046325684 0.0001205789449159056\n",
            "3.0797770023345947 2.9319372177124023 0.021856602281332016\n",
            "3.0247857570648193 2.9213993549346924 0.010688748210668564\n",
            "3.03643536567688 3.0712947845458984 0.0012151791015639901\n",
            "3.067782402038574 3.0999999046325684 0.0010379675077274442\n",
            "2.986201524734497 3.076308012008667 0.00811917893588543\n",
            "3.01193904876709 2.8958919048309326 0.013466939330101013\n",
            "2.9889376163482666 2.941307783126831 0.0022686009760946035\n",
            "3.056126356124878 3.07671856880188 0.0004240392299834639\n",
            "9 0.006237487250697392\n",
            "[0.17648650353057424, 0.016059269521938473, 0.012797999221211779, 0.010935028313758073, 0.009677853684232643, 0.0087286130459065, 0.007959463868778334, 0.0073084884051977505, 0.006741198009004452, 0.006237487250697392]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5YJeO-HmXz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "61f9fb78-e018-4ce8-a231-cc316a9e14f7"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.xticks(range(len(train_losses)))\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_losses, '-ro')\n",
        "\n",
        "# torch.save(model.state_dict(), 'model_save.pkl')\n",
        "# upload = drive.CreateFile({'title': 'model_save_5-2-20.pkl'})\n",
        "# upload.SetContentFile('model_save.pkl')\n",
        "# upload.Upload()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc32c9f4da0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5BcxiHTZCdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ef295eae-4fd0-4906-d017-93f6f9e40634"
      },
      "source": [
        "torch.no_grad()\n",
        "total = 0\n",
        "losses = []\n",
        "\n",
        "for X, Y in test:\n",
        "    # X, Y = [x.unsqueeze(0).to(device) for x in X], [y.to(device) for y in Y]\n",
        "    # for x, y in zip(X, Y):\n",
        "    #     pred = model(x)\n",
        "    #     loss = criterion(pred, y)\n",
        "        \n",
        "    #     # print('pred', pred.item())\n",
        "    #     # print('targ', y.item())\n",
        "    #     # print('loss', loss.item())\n",
        "        \n",
        "    #     total += 1\n",
        "    #     losses.append(loss.item())\n",
        "\n",
        "    X, Y = X.to(device), Y[0].to(device)\n",
        "    pred = model(X)\n",
        "    loss = criterion(pred, Y)\n",
        "\n",
        "    losses.append(loss.item() if loss.item() < 1 else 0)\n",
        "    total += 1\n",
        "    \n",
        "    # if total % 20 == 0:\n",
        "    if loss.item() > 0.1:\n",
        "        print(pred.item(), Y.item(), loss.item())\n",
        "\n",
        "test_loss = sum(losses) / total\n",
        "print(test_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.1883997917175293 2.789320230484009 0.1592644900083542\n",
            "3.328064441680908 2.9328255653381348 0.15621377527713776\n",
            "3.212629795074463 2.7979981899261475 0.17191936075687408\n",
            "3.251276731491089 2.895514965057373 0.12656643986701965\n",
            "3.144162893295288 2.8232040405273438 0.10301458835601807\n",
            "3.0630102157592773 2.714539051055908 0.12143215537071228\n",
            "3.2029030323028564 2.8370885848999023 0.13382020592689514\n",
            "3.282413959503174 2.917086601257324 0.13346408307552338\n",
            "0.012858712153788532\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}